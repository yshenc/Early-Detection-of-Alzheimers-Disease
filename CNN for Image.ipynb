{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A class to read the XML doc with each MRI scan. Each scan is included with an XML with various information.\n",
    "\"\"\"\n",
    "\n",
    "# parser\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "\n",
    "\n",
    "class XMLReader:\n",
    "    # Instantiates\n",
    "    def __init__(self, path):\n",
    "        # Safety check to make sure the file path is valid\n",
    "        try:\n",
    "            self.tree = ET.parse(path)\n",
    "            self.root = self.tree.getroot()\n",
    "        except IOError as ioerr:\n",
    "            print(\"Failed to parse\\n\")\n",
    "            print(ioerr)\n",
    "            print(\"\\n\")\n",
    "\n",
    "    # Returns 0 for NC, 1 for MCI, 2 for AD\n",
    "    def subject_status(self):\n",
    "        for i in self.root.iter(\"researchGroup\"):\n",
    "            if i.text == \"CN\":\n",
    "                return 0\n",
    "            elif i.text == \"MCI\":\n",
    "                return 1\n",
    "            elif i.text == \"AD\":\n",
    "                return 2\n",
    "\n",
    "    # Returns patient number\n",
    "    def subject_identifier(self):\n",
    "        for i in self.root.iter(\"subjectIdentifier\"):\n",
    "            return i.text\n",
    "\n",
    "    # checks to see if the current XML doc is for an MRI\n",
    "    def is_mri(self):\n",
    "        for i in self.root.iter(\"modality\"):\n",
    "            if i.text == \"MRI\":\n",
    "                return True\n",
    "\n",
    "    # finds the image ID\n",
    "    def getderiveduid(self):\n",
    "        for i in self.root.iter(\"imageUID\"):\n",
    "            return i.text\n",
    "\n",
    "    # finds a path to the respective scan from current directory\n",
    "    def path_to_scan(self, origin):\n",
    "        # first folder, patient number\n",
    "        id = self.subject_identifier()\n",
    "        path = \"/\" + id + \"/\"\n",
    "        # second folder, scan label\n",
    "        for i in self.root.iter(\"processedDataLabel\"):\n",
    "            label = i.text.split(\";\")\n",
    "            break\n",
    "        firstItem = True\n",
    "        for i in label:\n",
    "            if firstItem == True:\n",
    "                path = path + i.replace(\" \", \"\")\n",
    "                firstItem = False\n",
    "                continue\n",
    "            path = path + \"__\" + i.strip().replace(\" \", \"_\")\n",
    "        \n",
    "        '''\n",
    "        # third folder scan date\n",
    "        for i in self.root.iter(\"dateAcquired\"):\n",
    "            split = i.text.split(\" \")\n",
    "            lhs = split[0]\n",
    "            rhs = split[1]\n",
    "            break\n",
    "        path = path + \"/\" + lhs\n",
    "        rhsplit = rhs.split(\":\")\n",
    "        for i in rhsplit:\n",
    "            path = path + \"_\" + i\n",
    "        '''\n",
    "        # third folder scan date\n",
    "        item3 = os.listdir(origin + path)\n",
    "        loc = []\n",
    "        for i in item3:\n",
    "            if 'DS' not in i:\n",
    "                loc.append(i)\n",
    "        path = path + \"/\" + loc[0]\n",
    "        \n",
    "        # fourth folder, series number\n",
    "        for i in self.root.iter(\"seriesIdentifier\"):\n",
    "            sid = i.text\n",
    "            break\n",
    "        path = path + \"/\" + \"S\" + sid\n",
    "        \n",
    "        \n",
    "        # finally finds the scan, checks to see if its a .nii file\n",
    "        items = os.listdir(origin + path)\n",
    "        scans = 0\n",
    "        scan = []\n",
    "        for i in items:\n",
    "            curr = i.split(\".\")\n",
    "            if curr[len(curr) - 1] == \"nii\":\n",
    "                scan.append(i)\n",
    "                scans += 1\n",
    "        if scans > 1:\n",
    "            imageid = self.getderiveduid()\n",
    "            for i in scan:\n",
    "                parsed = i.replace(\".nii\", \"\").split(\"_\")\n",
    "                for x in parsed:\n",
    "                    if x == imageid:\n",
    "                        return path + \"/\" + i\n",
    "        return origin + path + \"/\" + scan[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputs(eval_data):\n",
    "    if eval_data is True:\n",
    "        data_dir = \"./ADNI/test_data\"\n",
    "    else:\n",
    "        data_dir = \"./ADNI/train_data\"\n",
    "    return img_inputs(eval_data=eval_data, data_dir=data_dir,batch_size=3)\n",
    "datadiction = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import nibabel as nib\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "width = 40\n",
    "height = 40\n",
    "depth = 20\n",
    "batch_index = 0\n",
    "ims = []\n",
    "filenames = []\n",
    "# user selection\n",
    "num_class = 3\n",
    "\n",
    "\n",
    "def img_inputs(eval_data, data_dir):\n",
    "    global ims\n",
    "    if not eval_data:\n",
    "        all = os.listdir(data_dir)\n",
    "        xmls = []\n",
    "        for x in all:\n",
    "            temp = x.split(\".\")\n",
    "            if temp[len(temp)-1] == \"xml\":\n",
    "                xmls.append(x)\n",
    "        for f in xmls:\n",
    "            r = XMLReader(data_dir+'/'+f)\n",
    "            p = r.path_to_scan(data_dir)\n",
    "            la = r.subject_status()\n",
    "            if not gfile.Exists(p):\n",
    "                raise ValueError('Failed to find file: ' + f)\n",
    "            else:\n",
    "                ims.append(str(la)+'||'+ p)\n",
    "    else:\n",
    "        all = os.listdir(data_dir)\n",
    "        xmls = []\n",
    "        for x in all:\n",
    "            temp = x.split(\".\")\n",
    "            if temp[len(temp)-1] == \"xml\":\n",
    "                xmls.append(x)\n",
    "        for f in xmls:\n",
    "            r = XMLReader(data_dir+'/'+f)\n",
    "            p = r.path_to_scan(data_dir)\n",
    "            la = r.subject_status()\n",
    "            if not gfile.Exists(p):\n",
    "                raise ValueError('Failed to find file: ' + f)\n",
    "            else:\n",
    "                ims.append(str(la)+'||'+p)\n",
    "    random.shuffle(ims)\n",
    "    return ims\n",
    "\n",
    "def inputs(eval_data):\n",
    "    if eval_data is True:\n",
    "        data_dir = \"./ADNI/test_data\"\n",
    "    else:\n",
    "        data_dir = \"./ADNI/train_data\"\n",
    "    return img_inputs(eval_data=eval_data, data_dir=data_dir)\n",
    "\n",
    "\n",
    "def get_image(sess, eval_data, batch_size):\n",
    "    global batch_index, filenames\n",
    "    if eval_data == True:\n",
    "        filenames = []\n",
    "    if len(filenames) == 0: \n",
    "        filenames = inputs(eval_data)\n",
    "    Max = len(filenames)\n",
    "    begin = batch_index\n",
    "    end = batch_index + batch_size\n",
    "    if end >= Max:\n",
    "        batch_index = 0\n",
    "        begin = batch_index\n",
    "        end = batch_index + batch_size\n",
    "    x_data = np.array([], np.float32)\n",
    "    y_data = np.zeros((batch_size, num_class)) # zero-filled list for 'one hot encoding'\n",
    "    index = 0\n",
    "    for i in range(begin, end):\n",
    "        imagePath = filenames[i].split('||')[1]\n",
    "        try: \n",
    "            image = datadiction[imagePath]\n",
    "        except:\n",
    "            FA_org = nib.load(imagePath)\n",
    "            if FA_org.get_data().shape[2] < 90:\n",
    "                print('gg')\n",
    "            FA_data = FA_org.get_data()[:,:,90:110].astype('float32')  # 256x256x166; numpy.ndarray\n",
    "            # TensorShape([Dimension(256), Dimension(256), Dimension(166)])                       \n",
    "            resized_image = tf.image.resize_images(images=FA_data, size=(width,height), method=1)\n",
    "            image = sess.run(resized_image)  # (256,256,166)\n",
    "            datadiction[imagePath] = image\n",
    "        x_data = np.append(x_data, np.asarray(image, dtype='float32')) # (image.data, dtype='float32')\n",
    "        y_data[index][int(filenames[i].split('||')[0])] = 1.0  # assign 1 to corresponding column (one hot encoding)\n",
    "        index+=1\n",
    "    batch_index += batch_size  # update index for the next batch\n",
    "    x_data_ = x_data.reshape(batch_size, height * width * depth)\n",
    "    return  x_data_, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuchenshen/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py:1662: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Tensor.get_shape of <tf.Tensor 'Reshape_2:0' shape=(?, 40, 40, 20, 1) dtype=float32>>\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'Relu_3:0' shape=(?, 40, 40, 20, 32) dtype=float32>>\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'MaxPool3D_2:0' shape=(?, 10, 10, 5, 32) dtype=float32>>\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'Relu_4:0' shape=(?, 10, 10, 5, 64) dtype=float32>>\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'MaxPool3D_3:0' shape=(?, 3, 3, 2, 64) dtype=float32>>\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'Reshape_3:0' shape=(?, 1152) dtype=float32>>\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'Relu_5:0' shape=(?, 1024) dtype=float32>>\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'dropout_1/mul:0' shape=(?, 1024) dtype=float32>>\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'add_7:0' shape=(?, 3) dtype=float32>>\n"
     ]
    }
   ],
   "source": [
    "nLabel = 3\n",
    "\n",
    "# Start TensorFlow InteractiveSession\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Placeholders (MNIST image:28x28pixels=784, label=10)\n",
    "xx = tf.placeholder(tf.float32, shape=[None, width*height*depth]) # [None, 28*28]\n",
    "yy = tf.placeholder(tf.float32, shape=[None, nLabel])  # [None, 10]\n",
    "\n",
    "def Weight(shape):\n",
    "    dist = tf.truncated_normal(shape,stddev=0.1)\n",
    "    return tf.Variable(dist)\n",
    "\n",
    "def Bias(shape):\n",
    "    dist = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(dist)\n",
    "\n",
    "def Convolution(x, W):\n",
    "    return tf.nn.conv3d(x, W, strides=[1, 1, 1, 1, 1], padding='SAME') # conv2d, [1, 1, 1, 1]\n",
    "\n",
    "\n",
    "def Max_pool(x): \n",
    "    return tf.nn.max_pool3d(x, ksize=[1, 4, 4, 4, 1], strides=[1, 4, 4, 4, 1], padding='SAME')\n",
    "\n",
    "\n",
    "W_conv1 = Weight([5, 5, 5, 1, 32])  \n",
    "b_conv1 = Bias([32]) \n",
    "\n",
    "\n",
    "x_image = tf.reshape(xx, [-1,width,height,depth,1]) \n",
    "print(x_image.get_shape) \n",
    "\n",
    "h_conv1 = tf.nn.relu(Convolution(x_image, W_conv1) + b_conv1)  \n",
    "print(h_conv1.get_shape) \n",
    "h_pool1 = Max_pool(h_conv1)  \n",
    "print(h_pool1.get_shape) \n",
    "\n",
    "\n",
    "W_conv2 = Weight([5, 5, 5, 32, 64]) \n",
    "b_conv2 = Bias([64]) # [64]\n",
    "\n",
    "h_conv2 = tf.nn.relu(Convolution(h_pool1, W_conv2) + b_conv2)  \n",
    "print(h_conv2.get_shape) \n",
    "h_pool2 = Max_pool(h_conv2) \n",
    "print(h_pool2.get_shape) \n",
    "\n",
    "\n",
    "W_fc1 = Weight([3*3*2*64, 1024]) \n",
    "b_fc1 = Bias([1024]) # [1024]]\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 3*3*2*64]) \n",
    "print(h_pool2_flat.get_shape)  \n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)  \n",
    "print(h_fc1.get_shape)\n",
    "\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "print(h_fc1_drop.get_shape)  # -> output: 1024\n",
    "\n",
    "W_fc2 = Weight([1024, nLabel]) # [1024, 10]\n",
    "b_fc2 = Bias([nLabel]) # [10]\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "print(y_conv.get_shape)  \n",
    "\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=yy, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(loss)  # 1e-4\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(yy,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "predic = tf.argmax(y_conv,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.535714\n",
      "cost: 12660.341\n",
      "test accuracy 0.583333\n",
      "step 3, training accuracy 0.264286\n",
      "cost: 30370.064\n",
      "test accuracy 0.25\n",
      "step 6, training accuracy 0.264286\n",
      "cost: 19925.217\n",
      "test accuracy 0.25\n",
      "step 9, training accuracy 0.535714\n",
      "cost: 13501.618\n",
      "test accuracy 0.583333\n",
      "step 12, training accuracy 0.535714\n",
      "cost: 14025.589\n",
      "test accuracy 0.583333\n",
      "step 15, training accuracy 0.264286\n",
      "cost: 4961.4526\n",
      "test accuracy 0.25\n",
      "step 18, training accuracy 0.285714\n",
      "cost: 8700.363\n",
      "test accuracy 0.25\n",
      "step 21, training accuracy 0.242857\n",
      "cost: 4468.594\n",
      "test accuracy 0.216667\n",
      "step 24, training accuracy 0.507143\n",
      "cost: 2025.6636\n",
      "test accuracy 0.6\n",
      "step 27, training accuracy 0.535714\n",
      "cost: 6754.704\n",
      "test accuracy 0.583333\n",
      "step 30, training accuracy 0.535714\n",
      "cost: 6337.8247\n",
      "test accuracy 0.583333\n",
      "step 33, training accuracy 0.564286\n",
      "cost: 1350.6521\n",
      "test accuracy 0.55\n",
      "step 36, training accuracy 0.264286\n",
      "cost: 3324.9548\n",
      "test accuracy 0.25\n",
      "step 39, training accuracy 0.264286\n",
      "cost: 4582.2646\n",
      "test accuracy 0.25\n",
      "step 42, training accuracy 0.364286\n",
      "cost: 806.51996\n",
      "test accuracy 0.216667\n",
      "step 45, training accuracy 0.25\n",
      "cost: 2522.608\n",
      "test accuracy 0.183333\n",
      "step 48, training accuracy 0.328571\n",
      "cost: 2096.9453\n",
      "test accuracy 0.25\n",
      "step 51, training accuracy 0.557143\n",
      "cost: 1419.9457\n",
      "test accuracy 0.566667\n",
      "step 54, training accuracy 0.535714\n",
      "cost: 1938.7274\n",
      "test accuracy 0.583333\n",
      "step 57, training accuracy 0.535714\n",
      "cost: 3244.3235\n",
      "test accuracy 0.583333\n",
      "step 60, training accuracy 0.535714\n",
      "cost: 2239.392\n",
      "test accuracy 0.583333\n",
      "step 63, training accuracy 0.55\n",
      "cost: 508.7583\n",
      "test accuracy 0.566667\n",
      "step 66, training accuracy 0.471429\n",
      "cost: 418.30292\n",
      "test accuracy 0.516667\n",
      "step 69, training accuracy 0.535714\n",
      "cost: 623.57434\n",
      "test accuracy 0.5\n",
      "step 72, training accuracy 0.492857\n",
      "cost: 860.5446\n",
      "test accuracy 0.5\n",
      "step 75, training accuracy 0.507143\n",
      "cost: 913.2916\n",
      "test accuracy 0.483333\n",
      "step 78, training accuracy 0.507143\n",
      "cost: 953.7095\n",
      "test accuracy 0.5\n",
      "step 81, training accuracy 0.407143\n",
      "cost: 734.6698\n",
      "test accuracy 0.416667\n",
      "step 84, training accuracy 0.35\n",
      "cost: 783.6237\n",
      "test accuracy 0.35\n",
      "step 87, training accuracy 0.264286\n",
      "cost: 951.75616\n",
      "test accuracy 0.316667\n",
      "step 90, training accuracy 0.25\n",
      "cost: 944.85626\n",
      "test accuracy 0.283333\n",
      "step 93, training accuracy 0.421429\n",
      "cost: 555.3521\n",
      "test accuracy 0.4\n",
      "step 96, training accuracy 0.478571\n",
      "cost: 459.13748\n",
      "test accuracy 0.516667\n",
      "step 99, training accuracy 0.535714\n",
      "cost: 411.67694\n",
      "test accuracy 0.666667\n",
      "step 102, training accuracy 0.528571\n",
      "cost: 566.2754\n",
      "test accuracy 0.616667\n",
      "step 105, training accuracy 0.535714\n",
      "cost: 655.57477\n",
      "test accuracy 0.633333\n",
      "step 108, training accuracy 0.428571\n",
      "cost: 471.01373\n",
      "test accuracy 0.35\n",
      "step 111, training accuracy 0.407143\n",
      "cost: 369.78354\n",
      "test accuracy 0.3\n",
      "step 114, training accuracy 0.492857\n",
      "cost: 281.92383\n",
      "test accuracy 0.433333\n",
      "step 117, training accuracy 0.5\n",
      "cost: 265.6671\n",
      "test accuracy 0.533333\n",
      "step 120, training accuracy 0.5\n",
      "cost: 239.02792\n",
      "test accuracy 0.5\n",
      "step 123, training accuracy 0.521429\n",
      "cost: 202.11238\n",
      "test accuracy 0.55\n",
      "step 126, training accuracy 0.6\n",
      "cost: 199.2049\n",
      "test accuracy 0.633333\n",
      "step 129, training accuracy 0.592857\n",
      "cost: 333.49173\n",
      "test accuracy 0.616667\n",
      "step 132, training accuracy 0.55\n",
      "cost: 629.54926\n",
      "test accuracy 0.616667\n",
      "step 135, training accuracy 0.535714\n",
      "cost: 738.9274\n",
      "test accuracy 0.6\n",
      "step 138, training accuracy 0.578571\n",
      "cost: 480.75876\n",
      "test accuracy 0.616667\n",
      "step 141, training accuracy 0.571429\n",
      "cost: 146.60063\n",
      "test accuracy 0.633333\n",
      "step 144, training accuracy 0.407143\n",
      "cost: 273.69617\n",
      "test accuracy 0.4\n",
      "step 147, training accuracy 0.328571\n",
      "cost: 398.209\n",
      "test accuracy 0.3\n",
      "step 150, training accuracy 0.328571\n",
      "cost: 321.27112\n",
      "test accuracy 0.3\n",
      "step 153, training accuracy 0.521429\n",
      "cost: 122.81031\n",
      "test accuracy 0.55\n",
      "step 156, training accuracy 0.607143\n",
      "cost: 120.78447\n",
      "test accuracy 0.633333\n",
      "step 159, training accuracy 0.578571\n",
      "cost: 237.23282\n",
      "test accuracy 0.583333\n",
      "step 162, training accuracy 0.571429\n",
      "cost: 281.0818\n",
      "test accuracy 0.583333\n",
      "step 165, training accuracy 0.578571\n",
      "cost: 294.80276\n",
      "test accuracy 0.583333\n",
      "step 168, training accuracy 0.578571\n",
      "cost: 269.4112\n",
      "test accuracy 0.583333\n",
      "step 171, training accuracy 0.578571\n",
      "cost: 167.09465\n",
      "test accuracy 0.583333\n",
      "step 174, training accuracy 0.514286\n",
      "cost: 112.26027\n",
      "test accuracy 0.516667\n",
      "step 177, training accuracy 0.435714\n",
      "cost: 178.41324\n",
      "test accuracy 0.316667\n",
      "step 180, training accuracy 0.35\n",
      "cost: 331.75192\n",
      "test accuracy 0.316667\n",
      "step 183, training accuracy 0.285714\n",
      "cost: 470.68744\n",
      "test accuracy 0.25\n",
      "step 186, training accuracy 0.3\n",
      "cost: 355.53882\n",
      "test accuracy 0.266667\n",
      "step 189, training accuracy 0.521429\n",
      "cost: 104.48553\n",
      "test accuracy 0.583333\n",
      "step 192, training accuracy 0.628571\n",
      "cost: 105.41719\n",
      "test accuracy 0.666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/yuchenshen/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-7-3c26e02c06c0>\", line 17, in <module>\n",
      "    train_step.run(feed_dict={xx: feature, yy: ylabel, keep_prob: 0.5})\n",
      "  File \"/Users/yuchenshen/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2366, in run\n",
      "    _run_using_default_session(self, feed_dict, self.graph, session)\n",
      "  File \"/Users/yuchenshen/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 5190, in _run_using_default_session\n",
      "    session.run(operation, feed_dict)\n",
      "  File \"/Users/yuchenshen/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 887, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/Users/yuchenshen/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1110, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/Users/yuchenshen/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1286, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/Users/yuchenshen/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1292, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/Users/yuchenshen/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1277, in _run_fn\n",
      "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "  File \"/Users/yuchenshen/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1367, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yuchenshen/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yuchenshen/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/yuchenshen/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/yuchenshen/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/yuchenshen/anaconda3/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/yuchenshen/anaconda3/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/yuchenshen/anaconda3/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/yuchenshen/anaconda3/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/Users/yuchenshen/venv/lib/python3.6/posixpath.py\", line 388, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/Users/yuchenshen/venv/lib/python3.6/posixpath.py\", line 422, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/Users/yuchenshen/venv/lib/python3.6/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "trainset = get_image(sess,False,140)\n",
    "testset = get_image(sess,True,60)\n",
    "\n",
    "# Include keep_prob in feed_dict to control dropout rate.\n",
    "for i in range(1000):\n",
    "    batch = get_image(sess,False,3)\n",
    "    feature = batch[0]\n",
    "    ylabel = batch[1]\n",
    "    #print(i)\n",
    "    # Logging every 100th iteration in the training process.\n",
    "    if i%3 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={xx:trainset[0], yy:trainset[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "        print('cost:',sess.run(loss,feed_dict={xx:trainset[0],yy:trainset[1],keep_prob:1.0}))\n",
    "        print(\"test accuracy %g\"%accuracy.eval(feed_dict={xx: testset[0], yy: testset[1], keep_prob: 1.0}))\n",
    "    train_step.run(feed_dict={xx: feature, yy: ylabel, keep_prob: 0.5})\n",
    "testset = get_image(sess,True,60)\n",
    "# Evaulate our accuracy on the test data\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={xx: testset[0], yy: testset[1], keep_prob: 1.0}))\n",
    "best = sess.run([predic],feed_dict={xx:testset[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
