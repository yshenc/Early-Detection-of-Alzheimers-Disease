{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuchenshen/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/Users/yuchenshen/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (2162) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Imputer, LabelEncoder, StandardScaler, scale\n",
    "df = pd.read_csv('./baseline_data.csv',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(628, 2163)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Catdata = df.loc[0:,'PTETHCAT':'APOE4'].join(df['PTGENDER']).join(df['imputed_genotype'])\n",
    "Numdata = df.loc[0:,:'Thickness..thickinthehead..2035'].join(df['AGE']).join(df['PTEDUCAT']).join(df['MMSE'])\n",
    "labels = df['DX.bl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(628, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Catdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(628, 2153)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Numdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Catdata.columns:\n",
    "    the_value = str(Catdata[i].mode().values[0])\n",
    "    Catdata[i].replace('NaN',the_value,inplace = True)\n",
    "    dummy_data = pd.get_dummies(Catdata[i], prefix=i+\"_\", drop_first=True)\n",
    "    Catdata = pd.concat([Catdata, dummy_data], axis=1)\n",
    "    Catdata.drop(i, axis=1, inplace=True)\n",
    "#for i in Numdata.columns:\n",
    "    #the_value = str(Numdata[i].median().values[0])\n",
    "    #Numdata[i].replace('NaN',the_value,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(labels)\n",
    "labels = le.transform(labels)\n",
    "labels = labels.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area.1002</th>\n",
       "      <th>area.1003</th>\n",
       "      <th>area.1005</th>\n",
       "      <th>area.1006</th>\n",
       "      <th>area.1007</th>\n",
       "      <th>area.1008</th>\n",
       "      <th>area.1009</th>\n",
       "      <th>area.1011</th>\n",
       "      <th>area.1012</th>\n",
       "      <th>area.1013</th>\n",
       "      <th>...</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>PTETHCAT__Not Hisp/Latino</th>\n",
       "      <th>PTETHCAT__Unknown</th>\n",
       "      <th>PTRACCAT__Black</th>\n",
       "      <th>PTRACCAT__White</th>\n",
       "      <th>APOE4__1</th>\n",
       "      <th>APOE4__2</th>\n",
       "      <th>PTGENDER__Male</th>\n",
       "      <th>imputed_genotype__True</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>612.577638</td>\n",
       "      <td>2514.366512</td>\n",
       "      <td>1652.050796</td>\n",
       "      <td>731.718725</td>\n",
       "      <td>3794.131041</td>\n",
       "      <td>5012.960558</td>\n",
       "      <td>4951.994756</td>\n",
       "      <td>5666.361234</td>\n",
       "      <td>2568.454160</td>\n",
       "      <td>3147.024829</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>735.292087</td>\n",
       "      <td>2435.629408</td>\n",
       "      <td>1947.966106</td>\n",
       "      <td>721.230657</td>\n",
       "      <td>4101.035394</td>\n",
       "      <td>4469.814924</td>\n",
       "      <td>4002.936490</td>\n",
       "      <td>5427.875646</td>\n",
       "      <td>2778.342103</td>\n",
       "      <td>3907.628206</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1080.976588</td>\n",
       "      <td>2190.801306</td>\n",
       "      <td>1613.620315</td>\n",
       "      <td>636.078912</td>\n",
       "      <td>5146.969073</td>\n",
       "      <td>6192.609394</td>\n",
       "      <td>4640.889149</td>\n",
       "      <td>6854.023127</td>\n",
       "      <td>3282.902615</td>\n",
       "      <td>3677.408865</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>840.850798</td>\n",
       "      <td>2293.601605</td>\n",
       "      <td>1599.807666</td>\n",
       "      <td>729.344575</td>\n",
       "      <td>3351.924971</td>\n",
       "      <td>4231.417941</td>\n",
       "      <td>3991.795466</td>\n",
       "      <td>5047.106646</td>\n",
       "      <td>2599.222056</td>\n",
       "      <td>3339.590461</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>592.882184</td>\n",
       "      <td>1827.195664</td>\n",
       "      <td>1479.821407</td>\n",
       "      <td>535.558408</td>\n",
       "      <td>3459.934118</td>\n",
       "      <td>5063.103074</td>\n",
       "      <td>3583.954659</td>\n",
       "      <td>4120.492969</td>\n",
       "      <td>2462.352998</td>\n",
       "      <td>2737.467877</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     area.1002    area.1003    area.1005   area.1006    area.1007  \\\n",
       "0   612.577638  2514.366512  1652.050796  731.718725  3794.131041   \n",
       "1   735.292087  2435.629408  1947.966106  721.230657  4101.035394   \n",
       "2  1080.976588  2190.801306  1613.620315  636.078912  5146.969073   \n",
       "3   840.850798  2293.601605  1599.807666  729.344575  3351.924971   \n",
       "4   592.882184  1827.195664  1479.821407  535.558408  3459.934118   \n",
       "\n",
       "     area.1008    area.1009    area.1011    area.1012    area.1013   ...    \\\n",
       "0  5012.960558  4951.994756  5666.361234  2568.454160  3147.024829   ...     \n",
       "1  4469.814924  4002.936490  5427.875646  2778.342103  3907.628206   ...     \n",
       "2  6192.609394  4640.889149  6854.023127  3282.902615  3677.408865   ...     \n",
       "3  4231.417941  3991.795466  5047.106646  2599.222056  3339.590461   ...     \n",
       "4  5063.103074  3583.954659  4120.492969  2462.352998  2737.467877   ...     \n",
       "\n",
       "   MMSE  PTETHCAT__Not Hisp/Latino  PTETHCAT__Unknown  PTRACCAT__Black  \\\n",
       "0    28                          1                  0                0   \n",
       "1    29                          1                  0                0   \n",
       "2    22                          1                  0                0   \n",
       "3    30                          1                  0                0   \n",
       "4    27                          1                  0                0   \n",
       "\n",
       "   PTRACCAT__White  APOE4__1  APOE4__2  PTGENDER__Male  \\\n",
       "0                1         1         0               1   \n",
       "1                1         0         0               0   \n",
       "2                1         0         1               1   \n",
       "3                1         0         0               0   \n",
       "4                1         1         0               0   \n",
       "\n",
       "   imputed_genotype__True  labels  \n",
       "0                       1     1.0  \n",
       "1                       1     1.0  \n",
       "2                       0     0.0  \n",
       "3                       1     1.0  \n",
       "4                       1     2.0  \n",
       "\n",
       "[5 rows x 2162 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "data = Numdata.join(Catdata)\n",
    "data['labels'] = labels\n",
    "#data = resample(data,n_samples=628, random_state = 2018)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = ([],[],[],[])\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.loc[:,:'imputed_genotype__True'], data['labels'], test_size = 0.2, random_state = 2018)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = pd.DataFrame(scaler.transform(X_train))\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2151</th>\n",
       "      <th>2152</th>\n",
       "      <th>2153</th>\n",
       "      <th>2154</th>\n",
       "      <th>2155</th>\n",
       "      <th>2156</th>\n",
       "      <th>2157</th>\n",
       "      <th>2158</th>\n",
       "      <th>2159</th>\n",
       "      <th>2160</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.674453</td>\n",
       "      <td>-0.679446</td>\n",
       "      <td>0.081322</td>\n",
       "      <td>-0.746656</td>\n",
       "      <td>-0.977341</td>\n",
       "      <td>-1.709378</td>\n",
       "      <td>-1.631854</td>\n",
       "      <td>-1.401668</td>\n",
       "      <td>-0.883885</td>\n",
       "      <td>-1.484730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130844</td>\n",
       "      <td>1.170398</td>\n",
       "      <td>0.135113</td>\n",
       "      <td>-0.077537</td>\n",
       "      <td>-0.224074</td>\n",
       "      <td>0.277945</td>\n",
       "      <td>-0.777067</td>\n",
       "      <td>-0.336277</td>\n",
       "      <td>-1.150684</td>\n",
       "      <td>0.597291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.858632</td>\n",
       "      <td>-0.706904</td>\n",
       "      <td>-0.762047</td>\n",
       "      <td>0.004010</td>\n",
       "      <td>-1.619124</td>\n",
       "      <td>-0.968373</td>\n",
       "      <td>-1.640428</td>\n",
       "      <td>-0.416259</td>\n",
       "      <td>-0.821928</td>\n",
       "      <td>-1.165071</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.536249</td>\n",
       "      <td>0.789620</td>\n",
       "      <td>0.135113</td>\n",
       "      <td>-0.077537</td>\n",
       "      <td>4.462809</td>\n",
       "      <td>-3.597839</td>\n",
       "      <td>1.286890</td>\n",
       "      <td>-0.336277</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>-1.674225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.377906</td>\n",
       "      <td>1.295648</td>\n",
       "      <td>-0.489598</td>\n",
       "      <td>-0.419993</td>\n",
       "      <td>0.603891</td>\n",
       "      <td>-0.077964</td>\n",
       "      <td>0.355101</td>\n",
       "      <td>-0.908562</td>\n",
       "      <td>0.075644</td>\n",
       "      <td>-0.327764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130844</td>\n",
       "      <td>0.408843</td>\n",
       "      <td>0.135113</td>\n",
       "      <td>-0.077537</td>\n",
       "      <td>-0.224074</td>\n",
       "      <td>0.277945</td>\n",
       "      <td>-0.777067</td>\n",
       "      <td>-0.336277</td>\n",
       "      <td>-1.150684</td>\n",
       "      <td>-1.674225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.043536</td>\n",
       "      <td>-1.294023</td>\n",
       "      <td>-1.172906</td>\n",
       "      <td>-0.558682</td>\n",
       "      <td>-0.338841</td>\n",
       "      <td>-0.591348</td>\n",
       "      <td>-0.510148</td>\n",
       "      <td>-1.332073</td>\n",
       "      <td>-0.478782</td>\n",
       "      <td>-0.831695</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.202831</td>\n",
       "      <td>-1.114267</td>\n",
       "      <td>0.135113</td>\n",
       "      <td>-0.077537</td>\n",
       "      <td>-0.224074</td>\n",
       "      <td>0.277945</td>\n",
       "      <td>-0.777067</td>\n",
       "      <td>-0.336277</td>\n",
       "      <td>-1.150684</td>\n",
       "      <td>0.597291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.069628</td>\n",
       "      <td>-0.025465</td>\n",
       "      <td>-0.344510</td>\n",
       "      <td>-1.905992</td>\n",
       "      <td>1.078735</td>\n",
       "      <td>0.456331</td>\n",
       "      <td>0.645210</td>\n",
       "      <td>0.291629</td>\n",
       "      <td>2.313630</td>\n",
       "      <td>1.157744</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.536505</td>\n",
       "      <td>-1.114267</td>\n",
       "      <td>0.135113</td>\n",
       "      <td>-0.077537</td>\n",
       "      <td>-0.224074</td>\n",
       "      <td>0.277945</td>\n",
       "      <td>-0.777067</td>\n",
       "      <td>-0.336277</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.597291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0 -0.674453 -0.679446  0.081322 -0.746656 -0.977341 -1.709378 -1.631854   \n",
       "1 -1.858632 -0.706904 -0.762047  0.004010 -1.619124 -0.968373 -1.640428   \n",
       "2  0.377906  1.295648 -0.489598 -0.419993  0.603891 -0.077964  0.355101   \n",
       "3 -0.043536 -1.294023 -1.172906 -0.558682 -0.338841 -0.591348 -0.510148   \n",
       "4 -0.069628 -0.025465 -0.344510 -1.905992  1.078735  0.456331  0.645210   \n",
       "\n",
       "       7         8         9       ...         2151      2152      2153  \\\n",
       "0 -1.401668 -0.883885 -1.484730    ...     0.130844  1.170398  0.135113   \n",
       "1 -0.416259 -0.821928 -1.165071    ...    -1.536249  0.789620  0.135113   \n",
       "2 -0.908562  0.075644 -0.327764    ...     0.130844  0.408843  0.135113   \n",
       "3 -1.332073 -0.478782 -0.831695    ...    -1.202831 -1.114267  0.135113   \n",
       "4  0.291629  2.313630  1.157744    ...    -2.536505 -1.114267  0.135113   \n",
       "\n",
       "       2154      2155      2156      2157      2158      2159      2160  \n",
       "0 -0.077537 -0.224074  0.277945 -0.777067 -0.336277 -1.150684  0.597291  \n",
       "1 -0.077537  4.462809 -3.597839  1.286890 -0.336277  0.869048 -1.674225  \n",
       "2 -0.077537 -0.224074  0.277945 -0.777067 -0.336277 -1.150684 -1.674225  \n",
       "3 -0.077537 -0.224074  0.277945 -0.777067 -0.336277 -1.150684  0.597291  \n",
       "4 -0.077537 -0.224074  0.277945 -0.777067 -0.336277  0.869048  0.597291  \n",
       "\n",
       "[5 rows x 2161 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.array(X_train)\n",
    "trainyy = np.array(y_train).reshape(-1,1)\n",
    "trainy = np.zeros([trainyy.shape[0],3])\n",
    "for i in range(trainyy.shape[0]):\n",
    "    trainy[i, int(trainyy[i])] = 1\n",
    "testX = np.array(X_test)\n",
    "testyy = np.array(y_test).reshape(-1,1)\n",
    "testy = np.zeros([testyy.shape[0],3])\n",
    "for i in range(testyy.shape[0]):\n",
    "    testy[i, int(testyy[i])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter1,Training loss: 1.0956194, Accuracy: 0.36055776,TAccuracy:0.3888889\n",
      "Iter2,Training loss: 1.0858626, Accuracy: 0.42629483,TAccuracy:0.44444445\n",
      "Iter3,Training loss: 1.0733498, Accuracy: 0.49203187,TAccuracy:0.5\n",
      "Iter4,Training loss: 1.0592997, Accuracy: 0.53386456,TAccuracy:0.52380955\n",
      "Iter5,Training loss: 1.0439098, Accuracy: 0.5278884,TAccuracy:0.53174603\n",
      "Iter6,Training loss: 1.0268135, Accuracy: 0.52988046,TAccuracy:0.515873\n",
      "Iter7,Training loss: 1.0071383, Accuracy: 0.5458167,TAccuracy:0.52380955\n",
      "Iter8,Training loss: 0.983598, Accuracy: 0.5976096,TAccuracy:0.53968257\n",
      "Iter9,Training loss: 0.9550369, Accuracy: 0.64143425,TAccuracy:0.56349206\n",
      "Iter10,Training loss: 0.9205682, Accuracy: 0.69123507,TAccuracy:0.5793651\n",
      "Iter11,Training loss: 0.88009465, Accuracy: 0.7410359,TAccuracy:0.5793651\n",
      "Iter12,Training loss: 0.8345541, Accuracy: 0.7868526,TAccuracy:0.5555556\n",
      "Iter13,Training loss: 0.78629917, Accuracy: 0.8286853,TAccuracy:0.515873\n",
      "Iter14,Training loss: 0.7406948, Accuracy: 0.85856575,TAccuracy:0.50793654\n",
      "Iter15,Training loss: 0.7015634, Accuracy: 0.8884462,TAccuracy:0.48412699\n",
      "Iter16,Training loss: 0.6699939, Accuracy: 0.90438247,TAccuracy:0.47619048\n",
      "Iter17,Training loss: 0.6460366, Accuracy: 0.92231077,TAccuracy:0.45238096\n",
      "Iter18,Training loss: 0.62685764, Accuracy: 0.936255,TAccuracy:0.43650794\n",
      "Iter19,Training loss: 0.6122738, Accuracy: 0.9482072,TAccuracy:0.43650794\n",
      "Iter20,Training loss: 0.6014384, Accuracy: 0.9561753,TAccuracy:0.43650794\n",
      "Iter21,Training loss: 0.59242374, Accuracy: 0.9621514,TAccuracy:0.46031746\n",
      "Iter22,Training loss: 0.58697206, Accuracy: 0.9681275,TAccuracy:0.45238096\n",
      "Iter23,Training loss: 0.5826715, Accuracy: 0.9721116,TAccuracy:0.44444445\n",
      "Iter24,Training loss: 0.57966757, Accuracy: 0.97410357,TAccuracy:0.45238096\n",
      "Iter25,Training loss: 0.578239, Accuracy: 0.97410357,TAccuracy:0.45238096\n",
      "Iter26,Training loss: 0.5770293, Accuracy: 0.9760956,TAccuracy:0.45238096\n",
      "Iter27,Training loss: 0.575954, Accuracy: 0.9760956,TAccuracy:0.46825397\n",
      "Iter28,Training loss: 0.57553154, Accuracy: 0.9760956,TAccuracy:0.47619048\n",
      "Iter29,Training loss: 0.5751566, Accuracy: 0.9760956,TAccuracy:0.48412699\n",
      "Iter30,Training loss: 0.57481277, Accuracy: 0.9760956,TAccuracy:0.47619048\n",
      "Iter31,Training loss: 0.5745982, Accuracy: 0.9760956,TAccuracy:0.47619048\n",
      "Iter32,Training loss: 0.57426393, Accuracy: 0.9760956,TAccuracy:0.47619048\n",
      "Iter33,Training loss: 0.5738699, Accuracy: 0.9760956,TAccuracy:0.47619048\n",
      "Iter34,Training loss: 0.57327163, Accuracy: 0.97808766,TAccuracy:0.47619048\n",
      "Iter35,Training loss: 0.5728179, Accuracy: 0.97808766,TAccuracy:0.47619048\n",
      "Iter36,Training loss: 0.5723565, Accuracy: 0.97808766,TAccuracy:0.47619048\n",
      "Iter37,Training loss: 0.57197124, Accuracy: 0.97808766,TAccuracy:0.48412699\n",
      "Iter38,Training loss: 0.5714198, Accuracy: 0.97808766,TAccuracy:0.4920635\n",
      "Iter39,Training loss: 0.57064676, Accuracy: 0.9800797,TAccuracy:0.4920635\n",
      "Iter40,Training loss: 0.57004863, Accuracy: 0.9800797,TAccuracy:0.4920635\n",
      "Iter41,Training loss: 0.5696107, Accuracy: 0.9800797,TAccuracy:0.4920635\n",
      "Iter42,Training loss: 0.5691313, Accuracy: 0.9820717,TAccuracy:0.4920635\n",
      "Iter43,Training loss: 0.5685735, Accuracy: 0.9820717,TAccuracy:0.4920635\n",
      "Iter44,Training loss: 0.5681214, Accuracy: 0.9820717,TAccuracy:0.4920635\n",
      "Iter45,Training loss: 0.5677002, Accuracy: 0.9820717,TAccuracy:0.4920635\n",
      "Iter46,Training loss: 0.56712127, Accuracy: 0.98406374,TAccuracy:0.4920635\n",
      "Iter47,Training loss: 0.5666272, Accuracy: 0.98406374,TAccuracy:0.4920635\n",
      "Iter48,Training loss: 0.56655663, Accuracy: 0.98406374,TAccuracy:0.4920635\n",
      "Iter49,Training loss: 0.5664704, Accuracy: 0.98406374,TAccuracy:0.4920635\n",
      "Iter50,Training loss: 0.56636953, Accuracy: 0.98406374,TAccuracy:0.48412699\n",
      "Iter51,Training loss: 0.5652964, Accuracy: 0.9860558,TAccuracy:0.48412699\n",
      "Iter52,Training loss: 0.56476533, Accuracy: 0.9860558,TAccuracy:0.4920635\n",
      "Iter53,Training loss: 0.56471896, Accuracy: 0.9860558,TAccuracy:0.4920635\n",
      "Iter54,Training loss: 0.5647329, Accuracy: 0.9860558,TAccuracy:0.47619048\n",
      "Iter55,Training loss: 0.5646933, Accuracy: 0.9860558,TAccuracy:0.46825397\n",
      "Iter56,Training loss: 0.56468, Accuracy: 0.9860558,TAccuracy:0.47619048\n",
      "Iter57,Training loss: 0.5646643, Accuracy: 0.9860558,TAccuracy:0.46825397\n",
      "Iter58,Training loss: 0.5646588, Accuracy: 0.9860558,TAccuracy:0.46825397\n",
      "Iter59,Training loss: 0.56463516, Accuracy: 0.9860558,TAccuracy:0.46825397\n",
      "Iter60,Training loss: 0.56462973, Accuracy: 0.9860558,TAccuracy:0.46825397\n",
      "Iter61,Training loss: 0.5646177, Accuracy: 0.9860558,TAccuracy:0.46825397\n",
      "Iter62,Training loss: 0.5646121, Accuracy: 0.9860558,TAccuracy:0.46825397\n",
      "Iter63,Training loss: 0.56460124, Accuracy: 0.9860558,TAccuracy:0.46825397\n",
      "Iter64,Training loss: 0.56459326, Accuracy: 0.9860558,TAccuracy:0.46031746\n",
      "Iter65,Training loss: 0.5645895, Accuracy: 0.9860558,TAccuracy:0.46031746\n",
      "Iter66,Training loss: 0.564581, Accuracy: 0.9860558,TAccuracy:0.46031746\n",
      "Iter67,Training loss: 0.5645738, Accuracy: 0.9860558,TAccuracy:0.46031746\n",
      "Iter68,Training loss: 0.5645652, Accuracy: 0.9860558,TAccuracy:0.46031746\n",
      "Iter69,Training loss: 0.5645529, Accuracy: 0.9860558,TAccuracy:0.46031746\n",
      "Iter70,Training loss: 0.5645398, Accuracy: 0.9860558,TAccuracy:0.46031746\n",
      "Iter71,Training loss: 0.5645181, Accuracy: 0.9860558,TAccuracy:0.46031746\n",
      "Iter72,Training loss: 0.56446487, Accuracy: 0.9860558,TAccuracy:0.46031746\n",
      "Iter73,Training loss: 0.5641617, Accuracy: 0.9860558,TAccuracy:0.46031746\n",
      "Iter74,Training loss: 0.5630791, Accuracy: 0.98804784,TAccuracy:0.46031746\n",
      "Iter75,Training loss: 0.5627588, Accuracy: 0.98804784,TAccuracy:0.46825397\n",
      "Iter76,Training loss: 0.562747, Accuracy: 0.98804784,TAccuracy:0.46825397\n",
      "Iter77,Training loss: 0.56274664, Accuracy: 0.98804784,TAccuracy:0.46825397\n",
      "Iter78,Training loss: 0.56274635, Accuracy: 0.98804784,TAccuracy:0.46825397\n",
      "Iter79,Training loss: 0.56274724, Accuracy: 0.98804784,TAccuracy:0.46825397\n",
      "Iter80,Training loss: 0.5627489, Accuracy: 0.98804784,TAccuracy:0.46825397\n",
      "Iter81,Training loss: 0.56275094, Accuracy: 0.98804784,TAccuracy:0.46825397\n",
      "Iter82,Training loss: 0.56275237, Accuracy: 0.98804784,TAccuracy:0.46825397\n",
      "Iter83,Training loss: 0.56274563, Accuracy: 0.98804784,TAccuracy:0.46825397\n",
      "Iter84,Training loss: 0.5627224, Accuracy: 0.98804784,TAccuracy:0.46825397\n",
      "Iter85,Training loss: 0.56266415, Accuracy: 0.98804784,TAccuracy:0.46825397\n",
      "Iter86,Training loss: 0.5625757, Accuracy: 0.98804784,TAccuracy:0.46825397\n",
      "Iter87,Training loss: 0.5626416, Accuracy: 0.98804784,TAccuracy:0.46825397\n",
      "Iter88,Training loss: 0.5626542, Accuracy: 0.98804784,TAccuracy:0.46825397\n",
      "Iter89,Training loss: 0.5626137, Accuracy: 0.98804784,TAccuracy:0.46825397\n",
      "Iter90,Training loss: 0.56256115, Accuracy: 0.98804784,TAccuracy:0.46825397\n",
      "Iter91,Training loss: 0.56257504, Accuracy: 0.98804784,TAccuracy:0.46825397\n",
      "Iter92,Training loss: 0.56258434, Accuracy: 0.98804784,TAccuracy:0.46825397\n",
      "Iter93,Training loss: 0.56258, Accuracy: 0.98804784,TAccuracy:0.46825397\n",
      "Iter94,Training loss: 0.56257015, Accuracy: 0.98804784,TAccuracy:0.46825397\n",
      "Iter95,Training loss: 0.5625596, Accuracy: 0.98804784,TAccuracy:0.46825397\n",
      "Iter96,Training loss: 0.56254995, Accuracy: 0.98804784,TAccuracy:0.46825397\n",
      "Iter97,Training loss: 0.5625414, Accuracy: 0.98804784,TAccuracy:0.46825397\n",
      "Iter98,Training loss: 0.5625337, Accuracy: 0.98804784,TAccuracy:0.47619048\n",
      "Iter99,Training loss: 0.5625261, Accuracy: 0.98804784,TAccuracy:0.47619048\n",
      "Iter100,Training loss: 0.5625174, Accuracy: 0.98804784,TAccuracy:0.47619048\n",
      "Iter101,Training loss: 0.5625045, Accuracy: 0.98804784,TAccuracy:0.47619048\n",
      "Iter102,Training loss: 0.5624779, Accuracy: 0.98804784,TAccuracy:0.47619048\n",
      "Iter103,Training loss: 0.5624212, Accuracy: 0.98804784,TAccuracy:0.47619048\n",
      "Iter104,Training loss: 0.5623338, Accuracy: 0.98804784,TAccuracy:0.47619048\n",
      "Iter105,Training loss: 0.56219643, Accuracy: 0.98804784,TAccuracy:0.47619048\n",
      "Iter106,Training loss: 0.56202585, Accuracy: 0.98804784,TAccuracy:0.47619048\n",
      "Iter107,Training loss: 0.5617605, Accuracy: 0.98804784,TAccuracy:0.47619048\n",
      "Iter108,Training loss: 0.5610172, Accuracy: 0.98804784,TAccuracy:0.46825397\n",
      "Iter109,Training loss: 0.5598336, Accuracy: 0.9920319,TAccuracy:0.46825397\n",
      "Iter110,Training loss: 0.5592619, Accuracy: 0.9920319,TAccuracy:0.47619048\n",
      "Iter111,Training loss: 0.5588786, Accuracy: 0.9920319,TAccuracy:0.47619048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter112,Training loss: 0.55849785, Accuracy: 0.9920319,TAccuracy:0.46825397\n",
      "Iter113,Training loss: 0.5580338, Accuracy: 0.9940239,TAccuracy:0.46825397\n",
      "Iter114,Training loss: 0.55763614, Accuracy: 0.9940239,TAccuracy:0.46825397\n",
      "Iter115,Training loss: 0.5574178, Accuracy: 0.9940239,TAccuracy:0.46825397\n",
      "Iter116,Training loss: 0.5573156, Accuracy: 0.9940239,TAccuracy:0.46825397\n",
      "Iter117,Training loss: 0.55727065, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter118,Training loss: 0.5572483, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter119,Training loss: 0.55723447, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter120,Training loss: 0.557223, Accuracy: 0.9940239,TAccuracy:0.46825397\n",
      "Iter121,Training loss: 0.5572134, Accuracy: 0.9940239,TAccuracy:0.46825397\n",
      "Iter122,Training loss: 0.55720466, Accuracy: 0.9940239,TAccuracy:0.46825397\n",
      "Iter123,Training loss: 0.55719715, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter124,Training loss: 0.55719024, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter125,Training loss: 0.5571841, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter126,Training loss: 0.5571788, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter127,Training loss: 0.55717397, Accuracy: 0.9940239,TAccuracy:0.48412699\n",
      "Iter128,Training loss: 0.5571697, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter129,Training loss: 0.55716574, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter130,Training loss: 0.55716234, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter131,Training loss: 0.55715907, Accuracy: 0.9940239,TAccuracy:0.46825397\n",
      "Iter132,Training loss: 0.55715615, Accuracy: 0.9940239,TAccuracy:0.46825397\n",
      "Iter133,Training loss: 0.55715334, Accuracy: 0.9940239,TAccuracy:0.46825397\n",
      "Iter134,Training loss: 0.55715084, Accuracy: 0.9940239,TAccuracy:0.46825397\n",
      "Iter135,Training loss: 0.5571484, Accuracy: 0.9940239,TAccuracy:0.46825397\n",
      "Iter136,Training loss: 0.5571462, Accuracy: 0.9940239,TAccuracy:0.46825397\n",
      "Iter137,Training loss: 0.5571442, Accuracy: 0.9940239,TAccuracy:0.46825397\n",
      "Iter138,Training loss: 0.5571422, Accuracy: 0.9940239,TAccuracy:0.46825397\n",
      "Iter139,Training loss: 0.55714047, Accuracy: 0.9940239,TAccuracy:0.46825397\n",
      "Iter140,Training loss: 0.5571386, Accuracy: 0.9940239,TAccuracy:0.46825397\n",
      "Iter141,Training loss: 0.5571371, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter142,Training loss: 0.5571356, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter143,Training loss: 0.55713403, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter144,Training loss: 0.5571326, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter145,Training loss: 0.5571313, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter146,Training loss: 0.55712986, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter147,Training loss: 0.55712867, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter148,Training loss: 0.55712754, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter149,Training loss: 0.5571263, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter150,Training loss: 0.5571251, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter151,Training loss: 0.55712396, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter152,Training loss: 0.5571228, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter153,Training loss: 0.5571218, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter154,Training loss: 0.55712074, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter155,Training loss: 0.55711967, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter156,Training loss: 0.5571187, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter157,Training loss: 0.55711764, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter158,Training loss: 0.5571167, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter159,Training loss: 0.55711573, Accuracy: 0.9940239,TAccuracy:0.48412699\n",
      "Iter160,Training loss: 0.55711466, Accuracy: 0.9940239,TAccuracy:0.48412699\n",
      "Iter161,Training loss: 0.5571136, Accuracy: 0.9940239,TAccuracy:0.48412699\n",
      "Iter162,Training loss: 0.5571126, Accuracy: 0.9940239,TAccuracy:0.4920635\n",
      "Iter163,Training loss: 0.5571113, Accuracy: 0.9940239,TAccuracy:0.4920635\n",
      "Iter164,Training loss: 0.5571102, Accuracy: 0.9940239,TAccuracy:0.48412699\n",
      "Iter165,Training loss: 0.5571089, Accuracy: 0.9940239,TAccuracy:0.48412699\n",
      "Iter166,Training loss: 0.55710757, Accuracy: 0.9940239,TAccuracy:0.48412699\n",
      "Iter167,Training loss: 0.5571061, Accuracy: 0.9940239,TAccuracy:0.48412699\n",
      "Iter168,Training loss: 0.55710435, Accuracy: 0.9940239,TAccuracy:0.48412699\n",
      "Iter169,Training loss: 0.5571025, Accuracy: 0.9940239,TAccuracy:0.48412699\n",
      "Iter170,Training loss: 0.5571005, Accuracy: 0.9940239,TAccuracy:0.48412699\n",
      "Iter171,Training loss: 0.55709803, Accuracy: 0.9940239,TAccuracy:0.48412699\n",
      "Iter172,Training loss: 0.5570953, Accuracy: 0.9940239,TAccuracy:0.48412699\n",
      "Iter173,Training loss: 0.5570923, Accuracy: 0.9940239,TAccuracy:0.48412699\n",
      "Iter174,Training loss: 0.5570886, Accuracy: 0.9940239,TAccuracy:0.48412699\n",
      "Iter175,Training loss: 0.5570843, Accuracy: 0.9940239,TAccuracy:0.48412699\n",
      "Iter176,Training loss: 0.55707914, Accuracy: 0.9940239,TAccuracy:0.48412699\n",
      "Iter177,Training loss: 0.5570724, Accuracy: 0.9940239,TAccuracy:0.48412699\n",
      "Iter178,Training loss: 0.55706364, Accuracy: 0.9940239,TAccuracy:0.48412699\n",
      "Iter179,Training loss: 0.55705094, Accuracy: 0.9940239,TAccuracy:0.48412699\n",
      "Iter180,Training loss: 0.55702937, Accuracy: 0.9940239,TAccuracy:0.4920635\n",
      "Iter181,Training loss: 0.5569737, Accuracy: 0.9940239,TAccuracy:0.4920635\n",
      "Iter182,Training loss: 0.5568778, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter183,Training loss: 0.5569023, Accuracy: 0.9940239,TAccuracy:0.47619048\n",
      "Iter184,Training loss: 0.556805, Accuracy: 0.9940239,TAccuracy:0.46825397\n",
      "Iter185,Training loss: 0.5559413, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter186,Training loss: 0.55541855, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter187,Training loss: 0.5553522, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter188,Training loss: 0.55526185, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter189,Training loss: 0.55515474, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter190,Training loss: 0.5551978, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter191,Training loss: 0.5552168, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter192,Training loss: 0.5552076, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter193,Training loss: 0.55516464, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter194,Training loss: 0.555198, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter195,Training loss: 0.5552044, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter196,Training loss: 0.55515146, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter197,Training loss: 0.5551763, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter198,Training loss: 0.55517554, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter199,Training loss: 0.5551575, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter200,Training loss: 0.555144, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter201,Training loss: 0.55516064, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter202,Training loss: 0.5551488, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter203,Training loss: 0.55513793, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter204,Training loss: 0.55514014, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter205,Training loss: 0.5551403, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter206,Training loss: 0.5551365, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter207,Training loss: 0.55513114, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter208,Training loss: 0.5551286, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter209,Training loss: 0.5551299, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter210,Training loss: 0.55513, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter211,Training loss: 0.5551265, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter212,Training loss: 0.55512315, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter213,Training loss: 0.5551223, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter214,Training loss: 0.5551226, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter215,Training loss: 0.555122, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter216,Training loss: 0.5551207, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter217,Training loss: 0.5551188, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter218,Training loss: 0.55511737, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter219,Training loss: 0.5551169, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter220,Training loss: 0.5551169, Accuracy: 0.99601597,TAccuracy:0.47619048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter221,Training loss: 0.5551164, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter222,Training loss: 0.5551152, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter223,Training loss: 0.5551141, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter224,Training loss: 0.55511343, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter225,Training loss: 0.555113, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter226,Training loss: 0.5551128, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter227,Training loss: 0.5551123, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter228,Training loss: 0.55511165, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter229,Training loss: 0.55511093, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter230,Training loss: 0.55511034, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter231,Training loss: 0.5551099, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter232,Training loss: 0.5551096, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter233,Training loss: 0.5551093, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter234,Training loss: 0.55510885, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter235,Training loss: 0.55510825, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter236,Training loss: 0.55510783, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter237,Training loss: 0.5551075, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter238,Training loss: 0.5551072, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter239,Training loss: 0.5551068, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter240,Training loss: 0.55510646, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter241,Training loss: 0.5551061, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter242,Training loss: 0.5551057, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter243,Training loss: 0.5551054, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter244,Training loss: 0.5551051, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter245,Training loss: 0.5551048, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter246,Training loss: 0.55510455, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter247,Training loss: 0.55510414, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter248,Training loss: 0.5551038, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter249,Training loss: 0.5551034, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter250,Training loss: 0.5551031, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter251,Training loss: 0.5551029, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter252,Training loss: 0.55510265, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter253,Training loss: 0.55510235, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter254,Training loss: 0.55510217, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter255,Training loss: 0.5551018, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter256,Training loss: 0.5551016, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter257,Training loss: 0.55510134, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter258,Training loss: 0.5551011, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter259,Training loss: 0.5551008, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter260,Training loss: 0.55510056, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter261,Training loss: 0.5551003, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter262,Training loss: 0.5551001, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter263,Training loss: 0.55509984, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter264,Training loss: 0.55509967, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter265,Training loss: 0.5550994, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter266,Training loss: 0.55509925, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter267,Training loss: 0.555099, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter268,Training loss: 0.5550988, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter269,Training loss: 0.5550986, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter270,Training loss: 0.55509835, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter271,Training loss: 0.5550981, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter272,Training loss: 0.555098, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter273,Training loss: 0.5550977, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter274,Training loss: 0.5550976, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter275,Training loss: 0.55509734, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter276,Training loss: 0.5550972, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter277,Training loss: 0.55509704, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter278,Training loss: 0.55509686, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter279,Training loss: 0.55509675, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter280,Training loss: 0.5550966, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter281,Training loss: 0.5550964, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter282,Training loss: 0.55509627, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter283,Training loss: 0.5550961, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter284,Training loss: 0.5550959, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter285,Training loss: 0.5550958, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter286,Training loss: 0.5550957, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter287,Training loss: 0.55509555, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter288,Training loss: 0.55509543, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter289,Training loss: 0.55509526, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter290,Training loss: 0.5550951, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter291,Training loss: 0.55509496, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter292,Training loss: 0.5550948, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter293,Training loss: 0.55509466, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter294,Training loss: 0.5550944, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter295,Training loss: 0.5550943, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter296,Training loss: 0.5550942, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter297,Training loss: 0.55509406, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter298,Training loss: 0.555094, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter299,Training loss: 0.5550938, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter300,Training loss: 0.5550937, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter301,Training loss: 0.5550936, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter302,Training loss: 0.55509347, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter303,Training loss: 0.55509335, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter304,Training loss: 0.5550932, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter305,Training loss: 0.5550931, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter306,Training loss: 0.555093, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter307,Training loss: 0.5550929, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter308,Training loss: 0.55509275, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter309,Training loss: 0.5550926, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter310,Training loss: 0.55509245, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter311,Training loss: 0.55509233, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter312,Training loss: 0.5550922, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter313,Training loss: 0.55509216, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter314,Training loss: 0.555092, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter315,Training loss: 0.555092, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter316,Training loss: 0.5550918, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter317,Training loss: 0.5550917, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter318,Training loss: 0.55509156, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter319,Training loss: 0.55509144, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter320,Training loss: 0.5550914, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter321,Training loss: 0.55509126, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter322,Training loss: 0.55509114, Accuracy: 0.99601597,TAccuracy:0.46825397\n",
      "Iter323,Training loss: 0.5550911, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter324,Training loss: 0.55509096, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter325,Training loss: 0.55509084, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter326,Training loss: 0.5550908, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter327,Training loss: 0.5550907, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter328,Training loss: 0.5550906, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter329,Training loss: 0.5550905, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter330,Training loss: 0.55509037, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter331,Training loss: 0.5550903, Accuracy: 0.99601597,TAccuracy:0.47619048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter332,Training loss: 0.5550901, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter333,Training loss: 0.5550901, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter334,Training loss: 0.55509, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter335,Training loss: 0.5550899, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter336,Training loss: 0.55508983, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter337,Training loss: 0.5550898, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter338,Training loss: 0.55508965, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter339,Training loss: 0.55508953, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter340,Training loss: 0.5550895, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter341,Training loss: 0.5550894, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter342,Training loss: 0.5550893, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter343,Training loss: 0.55508924, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter344,Training loss: 0.5550891, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter345,Training loss: 0.55508906, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter346,Training loss: 0.555089, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter347,Training loss: 0.5550889, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter348,Training loss: 0.55508876, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter349,Training loss: 0.5550887, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter350,Training loss: 0.5550886, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter351,Training loss: 0.5550885, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter352,Training loss: 0.5550884, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter353,Training loss: 0.5550884, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter354,Training loss: 0.5550883, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter355,Training loss: 0.55508816, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter356,Training loss: 0.5550881, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter357,Training loss: 0.55508804, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter358,Training loss: 0.5550879, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter359,Training loss: 0.5550879, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter360,Training loss: 0.5550878, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter361,Training loss: 0.5550877, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter362,Training loss: 0.5550876, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter363,Training loss: 0.55508757, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter364,Training loss: 0.5550875, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter365,Training loss: 0.55508745, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter366,Training loss: 0.55508727, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter367,Training loss: 0.55508727, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter368,Training loss: 0.55508715, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter369,Training loss: 0.55508703, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter370,Training loss: 0.55508703, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter371,Training loss: 0.5550869, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter372,Training loss: 0.55508685, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter373,Training loss: 0.5550868, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter374,Training loss: 0.55508673, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter375,Training loss: 0.5550867, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter376,Training loss: 0.55508655, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter377,Training loss: 0.55508655, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter378,Training loss: 0.5550865, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter379,Training loss: 0.55508643, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter380,Training loss: 0.5550863, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter381,Training loss: 0.5550862, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter382,Training loss: 0.5550862, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter383,Training loss: 0.5550861, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter384,Training loss: 0.5550861, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter385,Training loss: 0.55508596, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter386,Training loss: 0.55508596, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter387,Training loss: 0.55508584, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter388,Training loss: 0.5550857, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter389,Training loss: 0.55508566, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter390,Training loss: 0.55508554, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter391,Training loss: 0.55508554, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter392,Training loss: 0.5550854, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter393,Training loss: 0.55508536, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter394,Training loss: 0.55508536, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter395,Training loss: 0.5550853, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter396,Training loss: 0.5550852, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter397,Training loss: 0.5550852, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter398,Training loss: 0.55508506, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter399,Training loss: 0.55508506, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter400,Training loss: 0.55508494, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter401,Training loss: 0.55508494, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter402,Training loss: 0.5550848, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter403,Training loss: 0.55508476, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter404,Training loss: 0.5550847, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter405,Training loss: 0.55508465, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter406,Training loss: 0.55508465, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter407,Training loss: 0.5550846, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter408,Training loss: 0.55508447, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter409,Training loss: 0.55508447, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter410,Training loss: 0.55508435, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter411,Training loss: 0.5550843, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter412,Training loss: 0.5550842, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter413,Training loss: 0.5550841, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter414,Training loss: 0.5550841, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter415,Training loss: 0.55508405, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter416,Training loss: 0.555084, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter417,Training loss: 0.55508393, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter418,Training loss: 0.5550839, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter419,Training loss: 0.5550839, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter420,Training loss: 0.5550838, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter421,Training loss: 0.55508375, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter422,Training loss: 0.5550837, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter423,Training loss: 0.55508363, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter424,Training loss: 0.55508363, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter425,Training loss: 0.5550835, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter426,Training loss: 0.55508345, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter427,Training loss: 0.5550834, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter428,Training loss: 0.55508333, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter429,Training loss: 0.5550833, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter430,Training loss: 0.5550833, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter431,Training loss: 0.5550832, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter432,Training loss: 0.55508316, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter433,Training loss: 0.55508304, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter434,Training loss: 0.55508304, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter435,Training loss: 0.5550829, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter436,Training loss: 0.5550829, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter437,Training loss: 0.5550828, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter438,Training loss: 0.5550828, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter439,Training loss: 0.55508274, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter440,Training loss: 0.5550826, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter441,Training loss: 0.55508256, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter442,Training loss: 0.5550825, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter443,Training loss: 0.55508244, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter444,Training loss: 0.5550824, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter445,Training loss: 0.5550824, Accuracy: 0.99601597,TAccuracy:0.47619048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter446,Training loss: 0.5550823, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter447,Training loss: 0.55508226, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter448,Training loss: 0.5550822, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter449,Training loss: 0.5550821, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter450,Training loss: 0.555082, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter451,Training loss: 0.555082, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter452,Training loss: 0.55508196, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter453,Training loss: 0.5550819, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter454,Training loss: 0.55508184, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter455,Training loss: 0.5550818, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter456,Training loss: 0.5550817, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter457,Training loss: 0.5550817, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter458,Training loss: 0.5550817, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter459,Training loss: 0.5550816, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter460,Training loss: 0.5550816, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter461,Training loss: 0.5550815, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter462,Training loss: 0.5550815, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter463,Training loss: 0.5550814, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter464,Training loss: 0.5550813, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter465,Training loss: 0.5550813, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter466,Training loss: 0.55508125, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter467,Training loss: 0.55508125, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter468,Training loss: 0.5550811, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter469,Training loss: 0.5550811, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter470,Training loss: 0.55508107, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter471,Training loss: 0.555081, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter472,Training loss: 0.555081, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter473,Training loss: 0.5550809, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter474,Training loss: 0.5550809, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter475,Training loss: 0.5550809, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter476,Training loss: 0.5550808, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter477,Training loss: 0.5550808, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter478,Training loss: 0.55508065, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter479,Training loss: 0.55508065, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter480,Training loss: 0.5550806, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter481,Training loss: 0.55508053, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter482,Training loss: 0.55508053, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter483,Training loss: 0.55508053, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter484,Training loss: 0.5550804, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter485,Training loss: 0.5550804, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter486,Training loss: 0.5550804, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter487,Training loss: 0.5550803, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter488,Training loss: 0.5550803, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter489,Training loss: 0.55508024, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter490,Training loss: 0.5550802, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter491,Training loss: 0.5550802, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter492,Training loss: 0.5550802, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter493,Training loss: 0.55508006, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter494,Training loss: 0.55508006, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter495,Training loss: 0.55508006, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter496,Training loss: 0.55507994, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter497,Training loss: 0.55507994, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter498,Training loss: 0.5550799, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter499,Training loss: 0.5550799, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter500,Training loss: 0.5550798, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter501,Training loss: 0.55507976, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter502,Training loss: 0.5550797, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter503,Training loss: 0.5550797, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter504,Training loss: 0.5550797, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter505,Training loss: 0.5550795, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter506,Training loss: 0.5550795, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter507,Training loss: 0.5550795, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter508,Training loss: 0.5550795, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter509,Training loss: 0.5550794, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter510,Training loss: 0.5550794, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter511,Training loss: 0.55507934, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter512,Training loss: 0.55507934, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter513,Training loss: 0.5550793, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter514,Training loss: 0.5550793, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter515,Training loss: 0.5550792, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter516,Training loss: 0.55507916, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter517,Training loss: 0.55507916, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter518,Training loss: 0.5550791, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter519,Training loss: 0.55507904, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter520,Training loss: 0.55507904, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter521,Training loss: 0.555079, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter522,Training loss: 0.5550789, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter523,Training loss: 0.5550789, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter524,Training loss: 0.5550789, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter525,Training loss: 0.55507886, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter526,Training loss: 0.5550788, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter527,Training loss: 0.5550788, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter528,Training loss: 0.5550788, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter529,Training loss: 0.5550787, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter530,Training loss: 0.5550787, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter531,Training loss: 0.55507857, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter532,Training loss: 0.55507857, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter533,Training loss: 0.55507857, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter534,Training loss: 0.5550785, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter535,Training loss: 0.5550785, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter536,Training loss: 0.5550785, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter537,Training loss: 0.55507845, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter538,Training loss: 0.5550784, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter539,Training loss: 0.5550784, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter540,Training loss: 0.5550783, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter541,Training loss: 0.5550783, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter542,Training loss: 0.5550783, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter543,Training loss: 0.55507827, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter544,Training loss: 0.5550782, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter545,Training loss: 0.5550782, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter546,Training loss: 0.5550782, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter547,Training loss: 0.55507815, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter548,Training loss: 0.5550781, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter549,Training loss: 0.5550781, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter550,Training loss: 0.5550781, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter551,Training loss: 0.555078, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter552,Training loss: 0.55507797, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter553,Training loss: 0.5550779, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter554,Training loss: 0.5550779, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter555,Training loss: 0.55507785, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter556,Training loss: 0.5550778, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter557,Training loss: 0.5550778, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter558,Training loss: 0.5550778, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter559,Training loss: 0.5550778, Accuracy: 0.99601597,TAccuracy:0.47619048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter560,Training loss: 0.55507773, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter561,Training loss: 0.5550777, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter562,Training loss: 0.5550776, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter563,Training loss: 0.5550776, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter564,Training loss: 0.5550776, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter565,Training loss: 0.55507755, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter566,Training loss: 0.55507755, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter567,Training loss: 0.55507755, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter568,Training loss: 0.55507755, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter569,Training loss: 0.55507743, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter570,Training loss: 0.55507743, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter571,Training loss: 0.55507743, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter572,Training loss: 0.55507743, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter573,Training loss: 0.5550774, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter574,Training loss: 0.5550773, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter575,Training loss: 0.5550773, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter576,Training loss: 0.5550773, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter577,Training loss: 0.55507725, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter578,Training loss: 0.5550772, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter579,Training loss: 0.5550772, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter580,Training loss: 0.5550772, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter581,Training loss: 0.55507714, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter582,Training loss: 0.55507714, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter583,Training loss: 0.55507714, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter584,Training loss: 0.555077, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter585,Training loss: 0.555077, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter586,Training loss: 0.555077, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter587,Training loss: 0.55507696, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter588,Training loss: 0.55507696, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter589,Training loss: 0.55507696, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter590,Training loss: 0.5550769, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter591,Training loss: 0.5550769, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter592,Training loss: 0.5550769, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter593,Training loss: 0.55507684, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter594,Training loss: 0.55507684, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter595,Training loss: 0.5550768, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter596,Training loss: 0.5550767, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter597,Training loss: 0.5550767, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter598,Training loss: 0.5550767, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter599,Training loss: 0.5550767, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter600,Training loss: 0.55507666, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter601,Training loss: 0.55507666, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter602,Training loss: 0.55507654, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter603,Training loss: 0.55507654, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter604,Training loss: 0.55507654, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter605,Training loss: 0.55507654, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter606,Training loss: 0.5550765, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter607,Training loss: 0.5550764, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter608,Training loss: 0.5550764, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter609,Training loss: 0.5550764, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter610,Training loss: 0.55507636, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter611,Training loss: 0.55507636, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter612,Training loss: 0.5550763, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter613,Training loss: 0.5550763, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter614,Training loss: 0.5550763, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter615,Training loss: 0.5550763, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter616,Training loss: 0.55507624, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter617,Training loss: 0.55507624, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter618,Training loss: 0.5550762, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter619,Training loss: 0.5550762, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter620,Training loss: 0.5550762, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter621,Training loss: 0.55507606, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter622,Training loss: 0.55507606, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter623,Training loss: 0.55507606, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter624,Training loss: 0.55507606, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter625,Training loss: 0.55507606, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter626,Training loss: 0.55507606, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter627,Training loss: 0.55507594, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter628,Training loss: 0.55507594, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter629,Training loss: 0.55507594, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter630,Training loss: 0.55507594, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter631,Training loss: 0.55507594, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter632,Training loss: 0.5550758, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter633,Training loss: 0.5550758, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter634,Training loss: 0.5550758, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter635,Training loss: 0.5550758, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter636,Training loss: 0.5550758, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter637,Training loss: 0.55507576, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter638,Training loss: 0.5550757, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter639,Training loss: 0.5550757, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter640,Training loss: 0.5550757, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter641,Training loss: 0.5550757, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter642,Training loss: 0.5550757, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter643,Training loss: 0.55507565, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter644,Training loss: 0.5550756, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter645,Training loss: 0.5550756, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter646,Training loss: 0.5550756, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter647,Training loss: 0.5550755, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter648,Training loss: 0.5550755, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter649,Training loss: 0.5550755, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter650,Training loss: 0.5550755, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter651,Training loss: 0.55507547, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter652,Training loss: 0.5550754, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter653,Training loss: 0.5550754, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter654,Training loss: 0.5550754, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter655,Training loss: 0.5550754, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter656,Training loss: 0.55507535, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter657,Training loss: 0.55507535, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter658,Training loss: 0.55507535, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter659,Training loss: 0.5550753, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter660,Training loss: 0.5550753, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter661,Training loss: 0.5550752, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter662,Training loss: 0.5550752, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter663,Training loss: 0.5550752, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter664,Training loss: 0.5550752, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter665,Training loss: 0.5550752, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter666,Training loss: 0.5550751, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter667,Training loss: 0.5550751, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter668,Training loss: 0.5550751, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter669,Training loss: 0.5550751, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter670,Training loss: 0.5550751, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter671,Training loss: 0.5550751, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter672,Training loss: 0.55507505, Accuracy: 0.99601597,TAccuracy:0.47619048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter673,Training loss: 0.55507493, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter674,Training loss: 0.55507493, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter675,Training loss: 0.55507493, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter676,Training loss: 0.55507493, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter677,Training loss: 0.5550749, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter678,Training loss: 0.5550749, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter679,Training loss: 0.5550749, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter680,Training loss: 0.5550748, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter681,Training loss: 0.5550748, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter682,Training loss: 0.5550748, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter683,Training loss: 0.5550748, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter684,Training loss: 0.5550748, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter685,Training loss: 0.5550747, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter686,Training loss: 0.5550747, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter687,Training loss: 0.5550747, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter688,Training loss: 0.5550747, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter689,Training loss: 0.5550747, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter690,Training loss: 0.55507463, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter691,Training loss: 0.5550746, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter692,Training loss: 0.5550746, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter693,Training loss: 0.5550746, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter694,Training loss: 0.5550746, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter695,Training loss: 0.5550746, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter696,Training loss: 0.5550745, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter697,Training loss: 0.5550745, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter698,Training loss: 0.55507445, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter699,Training loss: 0.55507445, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter700,Training loss: 0.55507445, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter701,Training loss: 0.55507445, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter702,Training loss: 0.5550744, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter703,Training loss: 0.5550744, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter704,Training loss: 0.5550744, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter705,Training loss: 0.5550744, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter706,Training loss: 0.5550744, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter707,Training loss: 0.55507433, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter708,Training loss: 0.55507433, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter709,Training loss: 0.55507433, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter710,Training loss: 0.55507433, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter711,Training loss: 0.5550743, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter712,Training loss: 0.5550742, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter713,Training loss: 0.5550742, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter714,Training loss: 0.5550742, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter715,Training loss: 0.5550742, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter716,Training loss: 0.5550742, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter717,Training loss: 0.5550742, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter718,Training loss: 0.5550742, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter719,Training loss: 0.55507416, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter720,Training loss: 0.55507416, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter721,Training loss: 0.55507416, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter722,Training loss: 0.5550741, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter723,Training loss: 0.5550741, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter724,Training loss: 0.5550741, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter725,Training loss: 0.5550741, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter726,Training loss: 0.5550741, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter727,Training loss: 0.5550741, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter728,Training loss: 0.5550741, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter729,Training loss: 0.555074, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter730,Training loss: 0.555074, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter731,Training loss: 0.555074, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter732,Training loss: 0.555074, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter733,Training loss: 0.5550739, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter734,Training loss: 0.5550739, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter735,Training loss: 0.55507386, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter736,Training loss: 0.55507386, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter737,Training loss: 0.55507386, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter738,Training loss: 0.55507386, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter739,Training loss: 0.5550738, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter740,Training loss: 0.5550738, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter741,Training loss: 0.5550738, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter742,Training loss: 0.5550738, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter743,Training loss: 0.5550738, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter744,Training loss: 0.55507374, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter745,Training loss: 0.55507374, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter746,Training loss: 0.5550737, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter747,Training loss: 0.5550737, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter748,Training loss: 0.5550737, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter749,Training loss: 0.5550736, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter750,Training loss: 0.5550736, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter751,Training loss: 0.5550736, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter752,Training loss: 0.5550736, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter753,Training loss: 0.5550736, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter754,Training loss: 0.5550735, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter755,Training loss: 0.5550735, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter756,Training loss: 0.5550735, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter757,Training loss: 0.5550735, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter758,Training loss: 0.55507344, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter759,Training loss: 0.55507344, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter760,Training loss: 0.55507344, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter761,Training loss: 0.55507344, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter762,Training loss: 0.55507344, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter763,Training loss: 0.55507344, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter764,Training loss: 0.5550733, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter765,Training loss: 0.5550733, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter766,Training loss: 0.5550733, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter767,Training loss: 0.5550733, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter768,Training loss: 0.5550733, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter769,Training loss: 0.55507326, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter770,Training loss: 0.5550732, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter771,Training loss: 0.5550732, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter772,Training loss: 0.5550732, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter773,Training loss: 0.5550732, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter774,Training loss: 0.5550732, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter775,Training loss: 0.5550732, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter776,Training loss: 0.5550732, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter777,Training loss: 0.5550732, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter778,Training loss: 0.5550732, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter779,Training loss: 0.55507314, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter780,Training loss: 0.5550731, Accuracy: 0.99601597,TAccuracy:0.47619048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter781,Training loss: 0.5550731, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter782,Training loss: 0.5550731, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter783,Training loss: 0.5550731, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter784,Training loss: 0.5550731, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter785,Training loss: 0.5550731, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter786,Training loss: 0.555073, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter787,Training loss: 0.555073, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter788,Training loss: 0.555073, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter789,Training loss: 0.55507296, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter790,Training loss: 0.55507296, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter791,Training loss: 0.55507296, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter792,Training loss: 0.55507296, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter793,Training loss: 0.55507296, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter794,Training loss: 0.55507296, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter795,Training loss: 0.5550729, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter796,Training loss: 0.5550729, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter797,Training loss: 0.5550729, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter798,Training loss: 0.5550729, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter799,Training loss: 0.5550729, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter800,Training loss: 0.55507284, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter801,Training loss: 0.55507284, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter802,Training loss: 0.55507284, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter803,Training loss: 0.55507284, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter804,Training loss: 0.55507284, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter805,Training loss: 0.55507284, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter806,Training loss: 0.5550728, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter807,Training loss: 0.5550727, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter808,Training loss: 0.5550727, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter809,Training loss: 0.5550727, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter810,Training loss: 0.5550727, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter811,Training loss: 0.5550727, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter812,Training loss: 0.5550727, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter813,Training loss: 0.5550727, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter814,Training loss: 0.55507267, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter815,Training loss: 0.5550726, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter816,Training loss: 0.5550726, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter817,Training loss: 0.5550726, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter818,Training loss: 0.5550726, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter819,Training loss: 0.5550726, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter820,Training loss: 0.5550726, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter821,Training loss: 0.5550726, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter822,Training loss: 0.5550726, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter823,Training loss: 0.5550726, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter824,Training loss: 0.5550726, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter825,Training loss: 0.5550726, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter826,Training loss: 0.5550726, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter827,Training loss: 0.5550725, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter828,Training loss: 0.5550725, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter829,Training loss: 0.5550725, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter830,Training loss: 0.5550725, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter831,Training loss: 0.5550725, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter832,Training loss: 0.5550725, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter833,Training loss: 0.5550725, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter834,Training loss: 0.5550724, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter835,Training loss: 0.5550724, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter836,Training loss: 0.5550724, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter837,Training loss: 0.55507237, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter838,Training loss: 0.5550723, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter839,Training loss: 0.5550723, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter840,Training loss: 0.5550723, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter841,Training loss: 0.5550723, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter842,Training loss: 0.5550723, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter843,Training loss: 0.5550723, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter844,Training loss: 0.5550723, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter845,Training loss: 0.5550723, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter846,Training loss: 0.5550723, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter847,Training loss: 0.5550723, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter848,Training loss: 0.55507225, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter849,Training loss: 0.55507225, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter850,Training loss: 0.5550722, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter851,Training loss: 0.5550722, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter852,Training loss: 0.5550722, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter853,Training loss: 0.5550721, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter854,Training loss: 0.5550721, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter855,Training loss: 0.5550721, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter856,Training loss: 0.5550721, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter857,Training loss: 0.55507207, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter858,Training loss: 0.55507207, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter859,Training loss: 0.55507207, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter860,Training loss: 0.55507207, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter861,Training loss: 0.55507207, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter862,Training loss: 0.55507207, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter863,Training loss: 0.55507207, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter864,Training loss: 0.55507207, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter865,Training loss: 0.555072, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter866,Training loss: 0.55507195, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter867,Training loss: 0.55507195, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter868,Training loss: 0.55507195, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter869,Training loss: 0.55507195, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter870,Training loss: 0.55507195, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter871,Training loss: 0.55507195, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter872,Training loss: 0.55507195, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter873,Training loss: 0.55507195, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter874,Training loss: 0.55507195, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter875,Training loss: 0.5550719, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter876,Training loss: 0.5550719, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter877,Training loss: 0.5550719, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter878,Training loss: 0.5550719, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter879,Training loss: 0.5550719, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter880,Training loss: 0.5550719, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter881,Training loss: 0.55507183, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter882,Training loss: 0.55507183, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter883,Training loss: 0.55507183, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter884,Training loss: 0.55507183, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter885,Training loss: 0.55507183, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter886,Training loss: 0.55507183, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter887,Training loss: 0.5550718, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter888,Training loss: 0.5550717, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter889,Training loss: 0.5550717, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter890,Training loss: 0.5550717, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter891,Training loss: 0.5550717, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter892,Training loss: 0.5550717, Accuracy: 0.99601597,TAccuracy:0.47619048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter893,Training loss: 0.5550717, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter894,Training loss: 0.55507165, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter895,Training loss: 0.55507165, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter896,Training loss: 0.55507165, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter897,Training loss: 0.5550716, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter898,Training loss: 0.5550716, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter899,Training loss: 0.5550716, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter900,Training loss: 0.5550716, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter901,Training loss: 0.5550716, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter902,Training loss: 0.5550716, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter903,Training loss: 0.5550716, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter904,Training loss: 0.5550716, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter905,Training loss: 0.5550716, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter906,Training loss: 0.5550716, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter907,Training loss: 0.55507153, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter908,Training loss: 0.55507153, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter909,Training loss: 0.55507153, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter910,Training loss: 0.55507153, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter911,Training loss: 0.5550715, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter912,Training loss: 0.5550715, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter913,Training loss: 0.5550715, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter914,Training loss: 0.5550715, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter915,Training loss: 0.5550715, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter916,Training loss: 0.5550715, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter917,Training loss: 0.5550715, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter918,Training loss: 0.5550715, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter919,Training loss: 0.5550715, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter920,Training loss: 0.5550715, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter921,Training loss: 0.5550715, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter922,Training loss: 0.55507135, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter923,Training loss: 0.55507135, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter924,Training loss: 0.55507135, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter925,Training loss: 0.55507135, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter926,Training loss: 0.55507135, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter927,Training loss: 0.55507135, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter928,Training loss: 0.55507135, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter929,Training loss: 0.55507135, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter930,Training loss: 0.55507135, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter931,Training loss: 0.55507135, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter932,Training loss: 0.5550713, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter933,Training loss: 0.5550713, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter934,Training loss: 0.55507123, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter935,Training loss: 0.55507123, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter936,Training loss: 0.55507123, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter937,Training loss: 0.55507123, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter938,Training loss: 0.55507123, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter939,Training loss: 0.55507123, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter940,Training loss: 0.55507123, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter941,Training loss: 0.5550712, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter942,Training loss: 0.5550712, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter943,Training loss: 0.5550712, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter944,Training loss: 0.5550712, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter945,Training loss: 0.5550712, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter946,Training loss: 0.5550711, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter947,Training loss: 0.5550711, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter948,Training loss: 0.5550711, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter949,Training loss: 0.5550711, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter950,Training loss: 0.5550711, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter951,Training loss: 0.5550711, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter952,Training loss: 0.5550711, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter953,Training loss: 0.5550711, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter954,Training loss: 0.5550711, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter955,Training loss: 0.5550711, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter956,Training loss: 0.5550711, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter957,Training loss: 0.55507106, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter958,Training loss: 0.55507106, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter959,Training loss: 0.555071, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter960,Training loss: 0.555071, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter961,Training loss: 0.555071, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter962,Training loss: 0.555071, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter963,Training loss: 0.55507094, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter964,Training loss: 0.55507094, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter965,Training loss: 0.55507094, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter966,Training loss: 0.55507094, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter967,Training loss: 0.55507094, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter968,Training loss: 0.55507094, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter969,Training loss: 0.55507094, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter970,Training loss: 0.5550709, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter971,Training loss: 0.5550709, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter972,Training loss: 0.5550709, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter973,Training loss: 0.5550709, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter974,Training loss: 0.5550709, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter975,Training loss: 0.5550709, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter976,Training loss: 0.5550709, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter977,Training loss: 0.5550709, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter978,Training loss: 0.5550708, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter979,Training loss: 0.55507076, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter980,Training loss: 0.55507076, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter981,Training loss: 0.55507076, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter982,Training loss: 0.55507076, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter983,Training loss: 0.55507076, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter984,Training loss: 0.55507076, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter985,Training loss: 0.55507076, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter986,Training loss: 0.5550707, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter987,Training loss: 0.5550707, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter988,Training loss: 0.5550707, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter989,Training loss: 0.5550707, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter990,Training loss: 0.5550707, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter991,Training loss: 0.55507064, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter992,Training loss: 0.55507064, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter993,Training loss: 0.55507064, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter994,Training loss: 0.55507064, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter995,Training loss: 0.55507064, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter996,Training loss: 0.55507064, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter997,Training loss: 0.55507064, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter998,Training loss: 0.55507064, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter999,Training loss: 0.55507064, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1000,Training loss: 0.55507064, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1001,Training loss: 0.55507064, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1002,Training loss: 0.55507064, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1003,Training loss: 0.55507064, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1004,Training loss: 0.5550706, Accuracy: 0.99601597,TAccuracy:0.47619048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter1005,Training loss: 0.5550706, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1006,Training loss: 0.55507046, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1007,Training loss: 0.55507046, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1008,Training loss: 0.55507046, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1009,Training loss: 0.55507046, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1010,Training loss: 0.55507046, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1011,Training loss: 0.55507046, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1012,Training loss: 0.55507046, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1013,Training loss: 0.55507046, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1014,Training loss: 0.55507046, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1015,Training loss: 0.55507046, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1016,Training loss: 0.55507046, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1017,Training loss: 0.5550704, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1018,Training loss: 0.5550704, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1019,Training loss: 0.5550704, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1020,Training loss: 0.5550704, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1021,Training loss: 0.5550704, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1022,Training loss: 0.5550704, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1023,Training loss: 0.55507034, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1024,Training loss: 0.55507034, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1025,Training loss: 0.55507034, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1026,Training loss: 0.55507034, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1027,Training loss: 0.55507034, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1028,Training loss: 0.5550703, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1029,Training loss: 0.5550703, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1030,Training loss: 0.5550703, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1031,Training loss: 0.5550703, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1032,Training loss: 0.5550702, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1033,Training loss: 0.5550702, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1034,Training loss: 0.5550702, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1035,Training loss: 0.5550702, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1036,Training loss: 0.5550702, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1037,Training loss: 0.5550702, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1038,Training loss: 0.5550702, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1039,Training loss: 0.5550702, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1040,Training loss: 0.5550702, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1041,Training loss: 0.5550702, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1042,Training loss: 0.5550702, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1043,Training loss: 0.5550702, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1044,Training loss: 0.55507016, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1045,Training loss: 0.55507016, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1046,Training loss: 0.55507016, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1047,Training loss: 0.55507016, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1048,Training loss: 0.5550701, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1049,Training loss: 0.5550701, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1050,Training loss: 0.5550701, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1051,Training loss: 0.5550701, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1052,Training loss: 0.5550701, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1053,Training loss: 0.5550701, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1054,Training loss: 0.5550701, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1055,Training loss: 0.5550701, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1056,Training loss: 0.5550701, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1057,Training loss: 0.5550701, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1058,Training loss: 0.55507004, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1059,Training loss: 0.55507004, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1060,Training loss: 0.55507004, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1061,Training loss: 0.55507004, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1062,Training loss: 0.55507, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1063,Training loss: 0.55507, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1064,Training loss: 0.55507, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1065,Training loss: 0.55507, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1066,Training loss: 0.55507, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1067,Training loss: 0.55507, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1068,Training loss: 0.55507, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1069,Training loss: 0.55507, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1070,Training loss: 0.55507, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1071,Training loss: 0.5550699, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1072,Training loss: 0.5550699, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1073,Training loss: 0.5550699, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1074,Training loss: 0.5550699, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1075,Training loss: 0.5550699, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1076,Training loss: 0.55506986, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1077,Training loss: 0.55506986, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1078,Training loss: 0.55506986, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1079,Training loss: 0.55506986, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1080,Training loss: 0.55506986, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1081,Training loss: 0.55506986, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1082,Training loss: 0.5550698, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1083,Training loss: 0.5550698, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1084,Training loss: 0.5550698, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1085,Training loss: 0.5550698, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1086,Training loss: 0.55506974, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1087,Training loss: 0.55506974, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1088,Training loss: 0.55506974, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1089,Training loss: 0.55506974, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1090,Training loss: 0.55506974, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1091,Training loss: 0.55506974, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1092,Training loss: 0.55506974, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1093,Training loss: 0.55506974, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1094,Training loss: 0.55506974, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1095,Training loss: 0.5550697, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1096,Training loss: 0.5550697, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1097,Training loss: 0.5550697, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1098,Training loss: 0.5550697, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1099,Training loss: 0.5550697, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1100,Training loss: 0.5550696, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1101,Training loss: 0.5550696, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1102,Training loss: 0.5550696, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1103,Training loss: 0.5550696, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1104,Training loss: 0.5550696, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1105,Training loss: 0.55506957, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1106,Training loss: 0.55506957, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1107,Training loss: 0.55506957, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1108,Training loss: 0.5550695, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1109,Training loss: 0.5550695, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1110,Training loss: 0.5550695, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1111,Training loss: 0.55506945, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1112,Training loss: 0.55506945, Accuracy: 0.99601597,TAccuracy:0.47619048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter1113,Training loss: 0.55506945, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1114,Training loss: 0.55506945, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1115,Training loss: 0.55506945, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1116,Training loss: 0.55506945, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1117,Training loss: 0.55506945, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1118,Training loss: 0.55506945, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1119,Training loss: 0.55506945, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1120,Training loss: 0.55506945, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1121,Training loss: 0.5550694, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1122,Training loss: 0.5550694, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1123,Training loss: 0.5550694, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1124,Training loss: 0.5550694, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1125,Training loss: 0.5550693, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1126,Training loss: 0.5550693, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1127,Training loss: 0.5550693, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1128,Training loss: 0.5550693, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1129,Training loss: 0.5550693, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1130,Training loss: 0.5550693, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1131,Training loss: 0.5550693, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1132,Training loss: 0.5550693, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1133,Training loss: 0.55506927, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1134,Training loss: 0.55506927, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1135,Training loss: 0.55506927, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1136,Training loss: 0.55506927, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1137,Training loss: 0.55506927, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1138,Training loss: 0.55506927, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1139,Training loss: 0.55506927, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1140,Training loss: 0.55506927, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1141,Training loss: 0.55506927, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1142,Training loss: 0.5550692, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1143,Training loss: 0.5550692, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1144,Training loss: 0.5550692, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1145,Training loss: 0.5550692, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1146,Training loss: 0.5550692, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1147,Training loss: 0.5550692, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1148,Training loss: 0.5550692, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1149,Training loss: 0.55506915, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1150,Training loss: 0.55506915, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1151,Training loss: 0.5550691, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1152,Training loss: 0.5550691, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1153,Training loss: 0.5550691, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1154,Training loss: 0.5550691, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1155,Training loss: 0.5550691, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1156,Training loss: 0.5550691, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1157,Training loss: 0.555069, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1158,Training loss: 0.555069, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1159,Training loss: 0.555069, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1160,Training loss: 0.55506897, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1161,Training loss: 0.55506897, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1162,Training loss: 0.55506897, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1163,Training loss: 0.55506897, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1164,Training loss: 0.55506897, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1165,Training loss: 0.55506897, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1166,Training loss: 0.55506897, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1167,Training loss: 0.55506897, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1168,Training loss: 0.5550689, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1169,Training loss: 0.5550689, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1170,Training loss: 0.5550689, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1171,Training loss: 0.5550689, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1172,Training loss: 0.55506885, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1173,Training loss: 0.55506885, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1174,Training loss: 0.55506885, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1175,Training loss: 0.55506885, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1176,Training loss: 0.55506885, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1177,Training loss: 0.55506885, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1178,Training loss: 0.55506885, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1179,Training loss: 0.55506885, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1180,Training loss: 0.55506885, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1181,Training loss: 0.55506885, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1182,Training loss: 0.55506885, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1183,Training loss: 0.5550688, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1184,Training loss: 0.5550688, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1185,Training loss: 0.5550688, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1186,Training loss: 0.5550688, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1187,Training loss: 0.55506873, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1188,Training loss: 0.55506873, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1189,Training loss: 0.55506873, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1190,Training loss: 0.55506873, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1191,Training loss: 0.55506873, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1192,Training loss: 0.55506873, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1193,Training loss: 0.55506873, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1194,Training loss: 0.55506873, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1195,Training loss: 0.5550687, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1196,Training loss: 0.5550687, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1197,Training loss: 0.5550687, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1198,Training loss: 0.5550687, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1199,Training loss: 0.5550687, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1200,Training loss: 0.5550687, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1201,Training loss: 0.5550687, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1202,Training loss: 0.5550686, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1203,Training loss: 0.5550686, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1204,Training loss: 0.5550686, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1205,Training loss: 0.5550686, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1206,Training loss: 0.5550686, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1207,Training loss: 0.55506855, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1208,Training loss: 0.55506855, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1209,Training loss: 0.55506855, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1210,Training loss: 0.55506855, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1211,Training loss: 0.55506855, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1212,Training loss: 0.5550685, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1213,Training loss: 0.5550685, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1214,Training loss: 0.5550685, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1215,Training loss: 0.5550685, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1216,Training loss: 0.5550685, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1217,Training loss: 0.5550685, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1218,Training loss: 0.5550685, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1219,Training loss: 0.5550685, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1220,Training loss: 0.5550685, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1221,Training loss: 0.55506843, Accuracy: 0.99601597,TAccuracy:0.47619048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter1222,Training loss: 0.55506843, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1223,Training loss: 0.55506843, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1224,Training loss: 0.55506843, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1225,Training loss: 0.55506843, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1226,Training loss: 0.5550684, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1227,Training loss: 0.5550684, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1228,Training loss: 0.5550684, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1229,Training loss: 0.5550684, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1230,Training loss: 0.5550684, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1231,Training loss: 0.5550684, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1232,Training loss: 0.5550684, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1233,Training loss: 0.5550684, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1234,Training loss: 0.5550684, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1235,Training loss: 0.5550684, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1236,Training loss: 0.5550684, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1237,Training loss: 0.5550684, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1238,Training loss: 0.5550684, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1239,Training loss: 0.5550684, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1240,Training loss: 0.5550684, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1241,Training loss: 0.5550684, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1242,Training loss: 0.5550684, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1243,Training loss: 0.5550683, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1244,Training loss: 0.5550683, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1245,Training loss: 0.55506825, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1246,Training loss: 0.55506825, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1247,Training loss: 0.55506825, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1248,Training loss: 0.55506825, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1249,Training loss: 0.55506825, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1250,Training loss: 0.55506825, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1251,Training loss: 0.55506825, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1252,Training loss: 0.55506825, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1253,Training loss: 0.55506825, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1254,Training loss: 0.55506825, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1255,Training loss: 0.55506825, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1256,Training loss: 0.55506825, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1257,Training loss: 0.55506825, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1258,Training loss: 0.55506825, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1259,Training loss: 0.55506825, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1260,Training loss: 0.55506825, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1261,Training loss: 0.5550682, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1262,Training loss: 0.5550682, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1263,Training loss: 0.5550682, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1264,Training loss: 0.55506814, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1265,Training loss: 0.55506814, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1266,Training loss: 0.55506814, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1267,Training loss: 0.55506814, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1268,Training loss: 0.55506814, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1269,Training loss: 0.55506814, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1270,Training loss: 0.55506814, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1271,Training loss: 0.55506814, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1272,Training loss: 0.55506814, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1273,Training loss: 0.55506814, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1274,Training loss: 0.55506814, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1275,Training loss: 0.55506814, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1276,Training loss: 0.55506814, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1277,Training loss: 0.55506814, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1278,Training loss: 0.55506814, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1279,Training loss: 0.55506814, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1280,Training loss: 0.55506814, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1281,Training loss: 0.55506814, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1282,Training loss: 0.55506814, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1283,Training loss: 0.5550681, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1284,Training loss: 0.5550681, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1285,Training loss: 0.5550681, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1286,Training loss: 0.5550681, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1287,Training loss: 0.555068, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1288,Training loss: 0.555068, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1289,Training loss: 0.555068, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1290,Training loss: 0.555068, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1291,Training loss: 0.555068, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1292,Training loss: 0.555068, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1293,Training loss: 0.555068, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1294,Training loss: 0.555068, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1295,Training loss: 0.555068, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1296,Training loss: 0.55506796, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1297,Training loss: 0.55506796, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1298,Training loss: 0.55506796, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1299,Training loss: 0.55506796, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1300,Training loss: 0.55506796, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1301,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1302,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1303,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1304,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1305,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1306,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1307,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1308,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1309,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1310,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1311,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1312,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1313,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1314,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.47619048\n",
      "Iter1315,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1316,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1317,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1318,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1319,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1320,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1321,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1322,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1323,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1324,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1325,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1326,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1327,Training loss: 0.5550679, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1328,Training loss: 0.55506784, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1329,Training loss: 0.55506784, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1330,Training loss: 0.55506784, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1331,Training loss: 0.55506784, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1332,Training loss: 0.5550678, Accuracy: 0.99601597,TAccuracy:0.48412699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter1333,Training loss: 0.5550678, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1334,Training loss: 0.5550678, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1335,Training loss: 0.5550678, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1336,Training loss: 0.5550678, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1337,Training loss: 0.5550678, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1338,Training loss: 0.5550678, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1339,Training loss: 0.5550678, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1340,Training loss: 0.5550678, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1341,Training loss: 0.5550678, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1342,Training loss: 0.5550678, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1343,Training loss: 0.5550678, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1344,Training loss: 0.5550678, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1345,Training loss: 0.5550678, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1346,Training loss: 0.5550678, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1347,Training loss: 0.5550678, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1348,Training loss: 0.5550678, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1349,Training loss: 0.5550678, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1350,Training loss: 0.5550678, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1351,Training loss: 0.5550678, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1352,Training loss: 0.5550677, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1353,Training loss: 0.5550677, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1354,Training loss: 0.55506766, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1355,Training loss: 0.55506766, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1356,Training loss: 0.55506766, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1357,Training loss: 0.55506766, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1358,Training loss: 0.55506766, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1359,Training loss: 0.55506766, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1360,Training loss: 0.55506766, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1361,Training loss: 0.55506766, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1362,Training loss: 0.55506766, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1363,Training loss: 0.55506766, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1364,Training loss: 0.5550676, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1365,Training loss: 0.5550676, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1366,Training loss: 0.5550676, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1367,Training loss: 0.5550676, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1368,Training loss: 0.5550676, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1369,Training loss: 0.5550676, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1370,Training loss: 0.5550676, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1371,Training loss: 0.5550676, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1372,Training loss: 0.5550676, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1373,Training loss: 0.5550676, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1374,Training loss: 0.5550676, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1375,Training loss: 0.55506754, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1376,Training loss: 0.55506754, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1377,Training loss: 0.55506754, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1378,Training loss: 0.55506754, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1379,Training loss: 0.55506754, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1380,Training loss: 0.55506754, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1381,Training loss: 0.55506754, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1382,Training loss: 0.55506754, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1383,Training loss: 0.55506754, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1384,Training loss: 0.55506754, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1385,Training loss: 0.55506754, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1386,Training loss: 0.55506754, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1387,Training loss: 0.55506754, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1388,Training loss: 0.55506754, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1389,Training loss: 0.55506754, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1390,Training loss: 0.55506754, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1391,Training loss: 0.55506754, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1392,Training loss: 0.55506754, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1393,Training loss: 0.55506754, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1394,Training loss: 0.5550675, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1395,Training loss: 0.5550675, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1396,Training loss: 0.5550675, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1397,Training loss: 0.5550675, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1398,Training loss: 0.5550675, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1399,Training loss: 0.5550675, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1400,Training loss: 0.5550675, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1401,Training loss: 0.5550675, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1402,Training loss: 0.55506736, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1403,Training loss: 0.55506736, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1404,Training loss: 0.55506736, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1405,Training loss: 0.55506736, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1406,Training loss: 0.55506736, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1407,Training loss: 0.55506736, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1408,Training loss: 0.55506736, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1409,Training loss: 0.55506736, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1410,Training loss: 0.55506736, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1411,Training loss: 0.55506736, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1412,Training loss: 0.55506736, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1413,Training loss: 0.55506736, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1414,Training loss: 0.55506736, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1415,Training loss: 0.55506736, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1416,Training loss: 0.55506736, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1417,Training loss: 0.55506736, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1418,Training loss: 0.5550673, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1419,Training loss: 0.5550673, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1420,Training loss: 0.5550673, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1421,Training loss: 0.5550673, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1422,Training loss: 0.5550673, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1423,Training loss: 0.5550673, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1424,Training loss: 0.5550673, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1425,Training loss: 0.55506724, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1426,Training loss: 0.55506724, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1427,Training loss: 0.55506724, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1428,Training loss: 0.55506724, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1429,Training loss: 0.55506724, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1430,Training loss: 0.55506724, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1431,Training loss: 0.5550672, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1432,Training loss: 0.5550672, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1433,Training loss: 0.5550672, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1434,Training loss: 0.5550672, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1435,Training loss: 0.5550672, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1436,Training loss: 0.5550672, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1437,Training loss: 0.5550672, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1438,Training loss: 0.5550672, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1439,Training loss: 0.5550672, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1440,Training loss: 0.5550672, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1441,Training loss: 0.5550671, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1442,Training loss: 0.5550671, Accuracy: 0.99601597,TAccuracy:0.48412699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter1443,Training loss: 0.5550671, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1444,Training loss: 0.5550671, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1445,Training loss: 0.5550671, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1446,Training loss: 0.5550671, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1447,Training loss: 0.5550671, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1448,Training loss: 0.5550671, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1449,Training loss: 0.5550671, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1450,Training loss: 0.5550671, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1451,Training loss: 0.5550671, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1452,Training loss: 0.5550671, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1453,Training loss: 0.5550671, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1454,Training loss: 0.5550671, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1455,Training loss: 0.5550671, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1456,Training loss: 0.55506706, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1457,Training loss: 0.55506706, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1458,Training loss: 0.55506706, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1459,Training loss: 0.55506706, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1460,Training loss: 0.55506706, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1461,Training loss: 0.55506706, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1462,Training loss: 0.55506706, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1463,Training loss: 0.55506706, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1464,Training loss: 0.55506706, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1465,Training loss: 0.55506706, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1466,Training loss: 0.555067, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1467,Training loss: 0.555067, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1468,Training loss: 0.555067, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1469,Training loss: 0.555067, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1470,Training loss: 0.555067, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1471,Training loss: 0.555067, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1472,Training loss: 0.555067, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1473,Training loss: 0.555067, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1474,Training loss: 0.555067, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1475,Training loss: 0.555067, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1476,Training loss: 0.555067, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1477,Training loss: 0.55506694, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1478,Training loss: 0.55506694, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1479,Training loss: 0.55506694, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1480,Training loss: 0.55506694, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1481,Training loss: 0.55506694, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1482,Training loss: 0.55506694, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1483,Training loss: 0.55506694, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1484,Training loss: 0.55506694, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1485,Training loss: 0.55506694, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1486,Training loss: 0.55506694, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1487,Training loss: 0.55506694, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1488,Training loss: 0.55506694, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1489,Training loss: 0.55506694, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1490,Training loss: 0.55506694, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1491,Training loss: 0.55506694, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1492,Training loss: 0.55506694, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1493,Training loss: 0.55506694, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1494,Training loss: 0.55506694, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1495,Training loss: 0.55506694, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1496,Training loss: 0.55506694, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1497,Training loss: 0.55506694, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1498,Training loss: 0.55506694, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1499,Training loss: 0.5550669, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "Iter1500,Training loss: 0.5550669, Accuracy: 0.99601597,TAccuracy:0.48412699\n",
      "[array([1, 2, 2, 2, 2, 0, 2, 2, 1, 2, 0, 0, 0, 2, 2, 2, 0, 1, 0, 2, 2, 1,\n",
      "       2, 2, 0, 2, 2, 0, 0, 2, 2, 1, 2, 2, 0, 2, 0, 1, 1, 1, 2, 2, 2, 2,\n",
      "       2, 0, 2, 2, 0, 2, 1, 2, 1, 0, 1, 1, 2, 2, 2, 1, 0, 2, 1, 1, 0, 0,\n",
      "       2, 1, 1, 1, 2, 0, 2, 2, 2, 1, 1, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 0, 2, 1, 2, 2, 2, 0, 1, 2, 0, 2, 0, 1, 2, 0, 2, 0, 0, 1, 1,\n",
      "       2, 1, 2, 2, 0, 0, 1, 2, 1, 0, 0, 2, 2, 1, 1, 1])]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32,[None,2161])\n",
    "y = tf.placeholder(tf.float32,[None,3])\n",
    "\n",
    "W1 = tf.Variable(tf.truncated_normal([2161,200],stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([200])+0.1)\n",
    "z1 = tf.matmul(x,W1)+b1\n",
    "h1 = tf.nn.relu(z1)\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([200,50],stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([50])+0.1)\n",
    "z2 = tf.matmul(z1,W2)+b2\n",
    "h2 = tf.nn.tanh(z2)\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([50,10],stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([10])+0.1)\n",
    "z3 = tf.matmul(h2,W3)+b3\n",
    "h3 = tf.nn.tanh(z3)\n",
    "\n",
    "W4 = tf.Variable(tf.truncated_normal([10,3],stddev=0.1))\n",
    "b4 = tf.Variable(tf.zeros([3])+0.1)\n",
    "z4 = tf.matmul(h3,W4)+b4\n",
    "\n",
    "y_prediction = tf.nn.softmax(z4)\n",
    "\n",
    "#loss = tf.reduce_mean(-tf.reduce_sum(y * tf.log(y_prediction), reduction_indices=[1]))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = y, logits = y_prediction))\n",
    "#loss = tf.reduce_mean((y-y_prediction)**2)\n",
    "\n",
    "#Train = tf.train.GradientDescentOptimizer(0.0005).minimize(loss) #DOM:0.00001\n",
    "Train = tf.train.MomentumOptimizer(learning_rate=0.5,momentum = 0.9).minimize(loss)\n",
    "#Train = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "correct_p = tf.equal(tf.argmax(y,1),tf.argmax(y_prediction,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_p,tf.float32))\n",
    "prediction=tf.argmax(y_prediction,1)\n",
    "\n",
    "# using validation set to determine hyperparameters.\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(1500):\n",
    "        sess.run(Train,feed_dict={x:trainX,y:trainy})\n",
    "        acc = sess.run(accuracy,feed_dict={x:trainX, y:trainy})\n",
    "        tacc = sess.run(accuracy,feed_dict={x:testX, y:testy})\n",
    "        cost = sess.run(loss,feed_dict={x:trainX,y:trainy})\n",
    "        #print('batch: '+ str(batch)+',node: '+str(node)+', learning rate: '+str(lr))\n",
    "        print('Iter'+str(epoch+1)+',Training loss: '+str(cost)+', Accuracy: '+str(acc)+',TAccuracy:'+str(tacc))#+',f1_score:'+str(f_score))\n",
    "    best = sess.run([prediction],feed_dict={x:testX})\n",
    "    print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45593337959750163"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "best = best[0]\n",
    "besty = np.zeros([best.shape[0],3])\n",
    "for i in range(best.shape[0]):\n",
    "    besty[i, int(best[i])] = 1\n",
    "f1_score(testy,besty,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
